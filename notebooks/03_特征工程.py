{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ¹¿åœ°é«˜å…‰è°±ç‰¹å¾å·¥ç¨‹\n",
    "\n",
    "## æ¦‚è¿°\n",
    "æœ¬notebookå±•ç¤ºäº†æ¹¿åœ°é«˜å…‰è°±é¥æ„Ÿæ•°æ®çš„ç‰¹å¾å·¥ç¨‹è¿‡ç¨‹ï¼ŒåŒ…æ‹¬ï¼š\n",
    "- å…‰è°±ç‰¹å¾æå–\n",
    "- æ¤è¢«æŒ‡æ•°è®¡ç®—\n",
    "- çº¹ç†ç‰¹å¾åˆ†æ\n",
    "- ç©ºé—´ç‰¹å¾æå–\n",
    "- ç‰¹å¾é€‰æ‹©ä¸é™ç»´\n",
    "- ç‰¹å¾é‡è¦æ€§åˆ†æ\n",
    "\n",
    "ç‰¹å¾å·¥ç¨‹æ˜¯é«˜å…‰è°±åˆ†ç±»æˆåŠŸçš„å…³é”®æ­¥éª¤ï¼Œé€šè¿‡æå–æœ‰æ•ˆç‰¹å¾å¯ä»¥æ˜¾è‘—æé«˜åˆ†ç±»ç²¾åº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# å›¾åƒå¤„ç†å’Œå…‰è°±åˆ†æ\n",
    "import cv2\n",
    "from skimage import filters, feature, segmentation\n",
    "from skimage.morphology import disk\n",
    "import spectral as spy\n",
    "import rasterio\n",
    "\n",
    "# æœºå™¨å­¦ä¹ \n",
    "from sklearn.decomposition import PCA, FastICA, NMF\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, f_classif, mutual_info_classif,\n",
    "    RFE, SelectFromModel\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# ç§‘å­¦è®¡ç®—\n",
    "from scipy import ndimage, signal\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# è‡ªå®šä¹‰æ¨¡å—\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from wetland_classification.features import (\n",
    "    SpectralFeatureExtractor,\n",
    "    VegetationIndices,\n",
    "    TextureAnalyzer, \n",
    "    SpatialFeatureExtractor\n",
    ")\n",
    "from wetland_classification.data import DataLoader\n",
    "from wetland_classification.utils import visualization, logger\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾æ ·å¼\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# é…ç½®æ—¥å¿—\n",
    "logger = logger.setup_logger('feature_engineering', level='INFO')\n",
    "\n",
    "print(\"ç‰¹å¾å·¥ç¨‹ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. æ•°æ®åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½é¢„å¤„ç†åçš„æ•°æ®\n",
    "data_dir = Path('../data/processed')\n",
    "output_dir = Path('../data/features')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# æ•°æ®æ–‡ä»¶è·¯å¾„\n",
    "hyperspectral_file = data_dir / 'preprocessed_hyperspectral.tif'\n",
    "metadata_file = data_dir / 'preprocessed_metadata.json'\n",
    "ground_truth_file = Path('../data/raw/training_samples.shp')\n",
    "\n",
    "print(f\"é«˜å…‰è°±æ•°æ®: {hyperspectral_file}\")\n",
    "print(f\"å…ƒæ•°æ®: {metadata_file}\")\n",
    "print(f\"è®­ç»ƒæ ·æœ¬: {ground_truth_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ•°æ®\n",
    "loader = DataLoader()\n",
    "hyperspectral_data, metadata = loader.load_hyperspectral(str(hyperspectral_file))\n",
    "\n",
    "print(\"æ•°æ®åŸºæœ¬ä¿¡æ¯:\")\n",
    "print(f\"æ•°æ®å½¢çŠ¶: {hyperspectral_data.shape}\")\n",
    "print(f\"æ•°æ®ç±»å‹: {hyperspectral_data.dtype}\")\n",
    "print(f\"æ³¢æ®µæ•°é‡: {hyperspectral_data.shape[2]}\")\n",
    "print(f\"æ•°æ®èŒƒå›´: {hyperspectral_data.min():.4f} - {hyperspectral_data.max():.4f}\")\n",
    "\n",
    "# è·å–æ³¢é•¿ä¿¡æ¯\n",
    "wavelengths = metadata.get('wavelengths', np.arange(hyperspectral_data.shape[2]))\n",
    "print(f\"æ³¢é•¿èŒƒå›´: {wavelengths[0]:.1f} - {wavelengths[-1]:.1f} nm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½è®­ç»ƒæ ·æœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
    "if ground_truth_file.exists():\n",
    "    import geopandas as gpd\n",
    "    training_samples = gpd.read_file(ground_truth_file)\n",
    "    print(f\"\\nè®­ç»ƒæ ·æœ¬ä¿¡æ¯:\")\n",
    "    print(f\"æ ·æœ¬æ•°é‡: {len(training_samples)}\")\n",
    "    print(f\"ç±»åˆ«æ•°é‡: {training_samples['class'].nunique()}\")\n",
    "    print(f\"ç±»åˆ«åˆ†å¸ƒ:\\n{training_samples['class'].value_counts()}\")\n",
    "else:\n",
    "    print(\"æœªæ‰¾åˆ°è®­ç»ƒæ ·æœ¬æ–‡ä»¶\")\n",
    "    training_samples = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. å…‰è°±ç‰¹å¾æå–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºå…‰è°±ç‰¹å¾æå–å™¨\n",
    "spectral_extractor = SpectralFeatureExtractor(\n",
    "    wavelengths=wavelengths,\n",
    "    feature_types=[\n",
    "        'continuum_removal',\n",
    "        'spectral_derivatives', \n",
    "        'absorption_features',\n",
    "        'spectral_slope',\n",
    "        'spectral_curvature'\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"å¼€å§‹æå–å…‰è°±ç‰¹å¾...\")\n",
    "\n",
    "# æå–å…‰è°±ç‰¹å¾\n",
    "spectral_features = spectral_extractor.extract_features(hyperspectral_data)\n",
    "\n",
    "print(f\"å…‰è°±ç‰¹å¾æå–å®Œæˆ\")\n",
    "print(f\"ç‰¹å¾ç»´åº¦: {spectral_features.shape}\")\n",
    "print(f\"ç‰¹å¾åç§°: {spectral_extractor.get_feature_names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å…‰è°±ç‰¹å¾\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# é€‰æ‹©ä¸€ä¸ªå…¸å‹åƒç´ çš„å…‰è°±\n",
    "pixel_x, pixel_y = 150, 200\n",
    "original_spectrum = hyperspectral_data[pixel_x, pixel_y, :]\n",
    "\n",
    "# åŸå§‹å…‰è°±\n",
    "axes[0, 0].plot(wavelengths, original_spectrum, 'b-', linewidth=2)\n",
    "axes[0, 0].set_title('åŸå§‹å…‰è°±')\n",
    "axes[0, 0].set_xlabel('æ³¢é•¿ (nm)')\n",
    "axes[0, 0].set_ylabel('åå°„ç‡')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# è¿ç»­ç»Ÿå»é™¤\n",
    "continuum_removed = spectral_extractor.continuum_removal(original_spectrum, wavelengths)\n",
    "axes[0, 1].plot(wavelengths, continuum_removed, 'r-', linewidth=2)\n",
    "axes[0, 1].set_title('è¿ç»­ç»Ÿå»é™¤')\n",
    "axes[0, 1].set_xlabel('æ³¢é•¿ (nm)')\n",
    "axes[0, 1].set_ylabel('è¿ç»­ç»Ÿå»é™¤åå°„ç‡')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# ä¸€é˜¶å¯¼æ•°\n",
    "first_derivative = spectral_extractor.first_derivative(original_spectrum)\n",
    "axes[0, 2].plot(wavelengths[:-1], first_derivative, 'g-', linewidth=2)\n",
    "axes[0, 2].set_title('ä¸€é˜¶å¯¼æ•°')\n",
    "axes[0, 2].set_xlabel('æ³¢é•¿ (nm)')\n",
    "axes[0, 2].set_ylabel('ä¸€é˜¶å¯¼æ•°')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# äºŒé˜¶å¯¼æ•°\n",
    "second_derivative = spectral_extractor.second_derivative(original_spectrum)\n",
    "axes[1, 0].plot(wavelengths[:-2], second_derivative, 'm-', linewidth=2)\n",
    "axes[1, 0].set_title('äºŒé˜¶å¯¼æ•°')\n",
    "axes[1, 0].set_xlabel('æ³¢é•¿ (nm)')\n",
    "axes[1, 0].set_ylabel('äºŒé˜¶å¯¼æ•°')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# å¸æ”¶ç‰¹å¾æ·±åº¦\n",
    "absorption_depth = spectral_extractor.absorption_depth(original_spectrum, wavelengths)\n",
    "if len(absorption_depth) > 0:\n",
    "    axes[1, 1].bar(range(len(absorption_depth)), absorption_depth, color='orange', alpha=0.7)\n",
    "    axes[1, 1].set_title('å¸æ”¶ç‰¹å¾æ·±åº¦')\n",
    "    axes[1, 1].set_xlabel('å¸æ”¶ç‰¹å¾ç´¢å¼•')\n",
    "    axes[1, 1].set_ylabel('æ·±åº¦')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# å…‰è°±æ–œç‡\n",
    "red_edge_slope = spectral_extractor.red_edge_slope(original_spectrum, wavelengths)\n",
    "nir_slope = spectral_extractor.nir_slope(original_spectrum, wavelengths)\n",
    "slopes = [red_edge_slope, nir_slope]\n",
    "slope_names = ['Red Edge', 'NIR']\n",
    "axes[1, 2].bar(slope_names, slopes, color=['red', 'darkgreen'], alpha=0.7)\n",
    "axes[1, 2].set_title('å…‰è°±æ–œç‡')\n",
    "axes[1, 2].set_ylabel('æ–œç‡')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ¤è¢«æŒ‡æ•°è®¡ç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ¤è¢«æŒ‡æ•°è®¡ç®—å™¨\n",
    "vegetation_indices = VegetationIndices(wavelengths=wavelengths)\n",
    "\n",
    "print(\"å¼€å§‹è®¡ç®—æ¤è¢«æŒ‡æ•°...\")\n",
    "\n",
    "# è®¡ç®—å¸¸ç”¨æ¤è¢«æŒ‡æ•°\n",
    "vegetation_features = vegetation_indices.calculate_all_indices(hyperspectral_data)\n",
    "\n",
    "print(f\"æ¤è¢«æŒ‡æ•°è®¡ç®—å®Œæˆ\")\n",
    "print(f\"æ¤è¢«æŒ‡æ•°æ•°é‡: {len(vegetation_indices.get_index_names())}\")\n",
    "print(f\"æ¤è¢«æŒ‡æ•°åç§°: {vegetation_indices.get_index_names()}\")\n",
    "print(f\"æ¤è¢«ç‰¹å¾å½¢çŠ¶: {vegetation_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ä¸»è¦æ¤è¢«æŒ‡æ•°\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "index_names = vegetation_indices.get_index_names()\n",
    "main_indices = index_names[:12]  # æ˜¾ç¤ºå‰12ä¸ªä¸»è¦æŒ‡æ•°\n",
    "\n",
    "for i, index_name in enumerate(main_indices):\n",
    "    index_data = vegetation_features[:, :, i]\n",
    "    \n",
    "    # å¤„ç†å¼‚å¸¸å€¼\n",
    "    vmin, vmax = np.percentile(index_data[np.isfinite(index_data)], [2, 98])\n",
    "    \n",
    "    im = axes[i].imshow(index_data, cmap='RdYlGn', vmin=vmin, vmax=vmax)\n",
    "    axes[i].set_title(f'{index_name}', fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "    plt.colorbar(im, ax=axes[i], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†ææ¤è¢«æŒ‡æ•°ç»Ÿè®¡ç‰¹æ€§\n",
    "vegetation_stats = {}\n",
    "for i, index_name in enumerate(index_names):\n",
    "    index_data = vegetation_features[:, :, i]\n",
    "    valid_data = index_data[np.isfinite(index_data)]\n",
    "    \n",
    "    if len(valid_data) > 0:\n",
    "        vegetation_stats[index_name] = {\n",
    "            'mean': np.mean(valid_data),\n",
    "            'std': np.std(valid_data),\n",
    "            'min': np.min(valid_data),\n",
    "            'max': np.max(valid_data),\n",
    "            'skewness': skew(valid_data),\n",
    "            'kurtosis': kurtosis(valid_data)\n",
    "        }\n",
    "\n",
    "# è½¬æ¢ä¸ºDataFrameå¹¶æ˜¾ç¤º\n",
    "vegetation_stats_df = pd.DataFrame(vegetation_stats).T\n",
    "print(\"æ¤è¢«æŒ‡æ•°ç»Ÿè®¡ç‰¹æ€§:\")\n",
    "print(vegetation_stats_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. çº¹ç†ç‰¹å¾åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºçº¹ç†åˆ†æå™¨\n",
    "texture_analyzer = TextureAnalyzer(\n",
    "    methods=['glcm', 'lbp', 'gabor', 'laws'],\n",
    "    window_sizes=[3, 5, 7],\n",
    "    directions=[0, 45, 90, 135],\n",
    "    distances=[1, 2, 3]\n",
    ")\n",
    "\n",
    "print(\"å¼€å§‹æå–çº¹ç†ç‰¹å¾...\")\n",
    "\n",
    "# é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§æ³¢æ®µè¿›è¡Œçº¹ç†åˆ†æ\n",
    "texture_bands = [20, 60, 120, 180]  # ä¸åŒå…‰è°±åŒºåŸŸçš„ä»£è¡¨æ€§æ³¢æ®µ\n",
    "texture_features_list = []\n",
    "\n",
    "for band_idx in texture_bands:\n",
    "    band_data = hyperspectral_data[:, :, band_idx]\n",
    "    band_texture = texture_analyzer.extract_texture_features(band_data)\n",
    "    texture_features_list.append(band_texture)\n",
    "\n",
    "# åˆå¹¶æ‰€æœ‰çº¹ç†ç‰¹å¾\n",
    "texture_features = np.concatenate(texture_features_list, axis=2)\n",
    "\n",
    "print(f\"çº¹ç†ç‰¹å¾æå–å®Œæˆ\")\n",
    "print(f\"çº¹ç†ç‰¹å¾å½¢çŠ¶: {texture_features.shape}\")\n",
    "print(f\"æ¯ä¸ªæ³¢æ®µçº¹ç†ç‰¹å¾æ•°: {texture_features_list[0].shape[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–çº¹ç†ç‰¹å¾\n",
    "fig, axes = plt.subplots(4, 6, figsize=(24, 16))\n",
    "\n",
    "feature_names = texture_analyzer.get_feature_names()\n",
    "features_to_show = feature_names[:24]  # æ˜¾ç¤ºå‰24ä¸ªçº¹ç†ç‰¹å¾\n",
    "\n",
    "for i, feature_name in enumerate(features_to_show):\n",
    "    row, col = i // 6, i % 6\n",
    "    \n",
    "    # é€‰æ‹©ç¬¬ä¸€ä¸ªæ³¢æ®µçš„çº¹ç†ç‰¹å¾è¿›è¡Œæ˜¾ç¤º\n",
    "    feature_idx = i % texture_features_list[0].shape[2]\n",
    "    feature_data = texture_features_list[0][:, :, feature_idx]\n",
    "    \n",
    "    # å¤„ç†å¼‚å¸¸å€¼\n",
    "    vmin, vmax = np.percentile(feature_data[np.isfinite(feature_data)], [2, 98])\n",
    "    \n",
    "    im = axes[row, col].imshow(feature_data, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "    axes[row, col].set_title(f'{feature_name}', fontsize=8)\n",
    "    axes[row, col].axis('off')\n",
    "    plt.colorbar(im, ax=axes[row, col], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ç©ºé—´ç‰¹å¾æå–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºç©ºé—´ç‰¹å¾æå–å™¨\n",
    "spatial_extractor = SpatialFeatureExtractor(\n",
    "    methods=['morphological', 'geometric', 'contextual'],\n",
    "    kernel_sizes=[3, 5, 7, 9],\n",
    "    connectivity=8\n",
    ")\n",
    "\n",
    "print(\"å¼€å§‹æå–ç©ºé—´ç‰¹å¾...\")\n",
    "\n",
    "# è®¡ç®—ä¸»æˆåˆ†ç”¨äºç©ºé—´ç‰¹å¾æå–\n",
    "h, w, n_bands = hyperspectral_data.shape\n",
    "reshaped_data = hyperspectral_data.reshape(-1, n_bands)\n",
    "\n",
    "# PCAé™ç»´\n",
    "pca = PCA(n_components=10)\n",
    "pca_data = pca.fit_transform(reshaped_data)\n",
    "pca_image = pca_data.reshape(h, w, 10)\n",
    "\n",
    "print(f\"PCAè§£é‡Šæ–¹å·®æ¯”: {pca.explained_variance_ratio_[:5]}\")\n",
    "\n",
    "# æå–ç©ºé—´ç‰¹å¾\n",
    "spatial_features = spatial_extractor.extract_features(pca_image[:, :, :3])  # ä½¿ç”¨å‰3ä¸ªä¸»æˆåˆ†\n",
    "\n",
    "print(f\"ç©ºé—´ç‰¹å¾æå–å®Œæˆ\")\n",
    "print(f\"ç©ºé—´ç‰¹å¾å½¢çŠ¶: {spatial_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ç©ºé—´ç‰¹å¾\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "spatial_feature_names = spatial_extractor.get_feature_names()\n",
    "features_to_show = min(12, spatial_features.shape[2])\n",
    "\n",
    "for i in range(features_to_show):\n",
    "    feature_data = spatial_features[:, :, i]\n",
    "    \n",
    "    # å¤„ç†å¼‚å¸¸å€¼\n",
    "    vmin, vmax = np.percentile(feature_data[np.isfinite(feature_data)], [2, 98])\n",
    "    \n",
    "    im = axes[i].imshow(feature_data, cmap='plasma', vmin=vmin, vmax=vmax)\n",
    "    if i < len(spatial_feature_names):\n",
    "        axes[i].set_title(f'{spatial_feature_names[i]}', fontsize=10)\n",
    "    else:\n",
    "        axes[i].set_title(f'Spatial Feature {i+1}', fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "    plt.colorbar(im, ax=axes[i], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ç‰¹å¾èåˆä¸ç»„ç»‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾èåˆ\n",
    "print(\"å¼€å§‹ç‰¹å¾èåˆ...\")\n",
    "\n",
    "# ç¡®ä¿æ‰€æœ‰ç‰¹å¾å…·æœ‰ç›¸åŒçš„ç©ºé—´ç»´åº¦\n",
    "h, w = hyperspectral_data.shape[:2]\n",
    "\n",
    "# é‡å¡‘ç‰¹å¾ä¸ºäºŒç»´æ•°ç»„ (åƒç´ æ•°, ç‰¹å¾æ•°)\n",
    "features_list = []\n",
    "feature_names_list = []\n",
    "\n",
    "# 1. åŸå§‹å…‰è°±ç‰¹å¾\n",
    "original_features = hyperspectral_data.reshape(-1, hyperspectral_data.shape[2])\n",
    "features_list.append(original_features)\n",
    "feature_names_list.extend([f'Band_{i+1}' for i in range(hyperspectral_data.shape[2])])\n",
    "\n",
    "# 2. å…‰è°±è¡ç”Ÿç‰¹å¾\n",
    "if spectral_features.ndim == 3:\n",
    "    spectral_features_2d = spectral_features.reshape(-1, spectral_features.shape[2])\n",
    "    features_list.append(spectral_features_2d)\n",
    "    feature_names_list.extend(spectral_extractor.get_feature_names())\n",
    "\n",
    "# 3. æ¤è¢«æŒ‡æ•°\n",
    "vegetation_features_2d = vegetation_features.reshape(-1, vegetation_features.shape[2])\n",
    "features_list.append(vegetation_features_2d)\n",
    "feature_names_list.extend(vegetation_indices.get_index_names())\n",
    "\n",
    "# 4. çº¹ç†ç‰¹å¾\n",
    "texture_features_2d = texture_features.reshape(-1, texture_features.shape[2])\n",
    "features_list.append(texture_features_2d)\n",
    "texture_names = [f'Texture_{i+1}' for i in range(texture_features.shape[2])]\n",
    "feature_names_list.extend(texture_names)\n",
    "\n",
    "# 5. ç©ºé—´ç‰¹å¾\n",
    "spatial_features_2d = spatial_features.reshape(-1, spatial_features.shape[2])\n",
    "features_list.append(spatial_features_2d)\n",
    "spatial_names = [f'Spatial_{i+1}' for i in range(spatial_features.shape[2])]\n",
    "feature_names_list.extend(spatial_names)\n",
    "\n",
    "# åˆå¹¶æ‰€æœ‰ç‰¹å¾\n",
    "all_features = np.concatenate(features_list, axis=1)\n",
    "\n",
    "print(f\"ç‰¹å¾èåˆå®Œæˆ\")\n",
    "print(f\"æ€»ç‰¹å¾æ•°é‡: {all_features.shape[1]}\")\n",
    "print(f\"ç‰¹å¾åˆ†å¸ƒ:\")\n",
    "print(f\"  - åŸå§‹å…‰è°±: {original_features.shape[1]}\")\n",
    "print(f\"  - å…‰è°±è¡ç”Ÿ: {spectral_features_2d.shape[1] if spectral_features.ndim == 3 else 0}\")\n",
    "print(f\"  - æ¤è¢«æŒ‡æ•°: {vegetation_features_2d.shape[1]}\")\n",
    "print(f\"  - çº¹ç†ç‰¹å¾: {texture_features_2d.shape[1]}\")\n",
    "print(f\"  - ç©ºé—´ç‰¹å¾: {spatial_features_2d.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾é¢„å¤„ç†\n",
    "print(\"å¼€å§‹ç‰¹å¾é¢„å¤„ç†...\")\n",
    "\n",
    "# å¤„ç†æ— æ•ˆå€¼\n",
    "all_features = np.nan_to_num(all_features, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "# æ ‡å‡†åŒ–\n",
    "scaler = StandardScaler()\n",
    "all_features_scaled = scaler.fit_transform(all_features)\n",
    "\n",
    "print(f\"ç‰¹å¾é¢„å¤„ç†å®Œæˆ\")\n",
    "print(f\"æ ‡å‡†åŒ–åç‰¹å¾ç»Ÿè®¡:\")\n",
    "print(f\"  - å‡å€¼: {np.mean(all_features_scaled):.6f}\")\n",
    "print(f\"  - æ ‡å‡†å·®: {np.std(all_features_scaled):.6f}\")\n",
    "print(f\"  - æœ€å°å€¼: {np.min(all_features_scaled):.3f}\")\n",
    "print(f\"  - æœ€å¤§å€¼: {np.max(all_features_scaled):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ç‰¹å¾é€‰æ‹©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚æœæœ‰è®­ç»ƒæ ·æœ¬ï¼Œè¿›è¡Œç›‘ç£ç‰¹å¾é€‰æ‹©\n",
    "if training_samples is not None:\n",
    "    print(\"å¼€å§‹ç›‘ç£ç‰¹å¾é€‰æ‹©...\")\n",
    "    \n",
    "    # æå–è®­ç»ƒæ ·æœ¬å¯¹åº”çš„ç‰¹å¾å’Œæ ‡ç­¾\n",
    "    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æ ·æœ¬æ ¼å¼è¿›è¡Œè°ƒæ•´\n",
    "    # å‡è®¾æˆ‘ä»¬éšæœºé€‰æ‹©ä¸€äº›æ ·æœ¬ä½œä¸ºç¤ºä¾‹\n",
    "    n_samples = min(5000, all_features_scaled.shape[0])\n",
    "    sample_indices = np.random.choice(all_features_scaled.shape[0], n_samples, replace=False)\n",
    "    X_sample = all_features_scaled[sample_indices]\n",
    "    \n",
    "    # æ¨¡æ‹Ÿæ ‡ç­¾ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦ä»è®­ç»ƒæ ·æœ¬ä¸­æå–ï¼‰\n",
    "    y_sample = np.random.randint(0, 5, n_samples)  # å‡è®¾5ä¸ªç±»åˆ«\n",
    "    \n",
    "    # 1. åŸºäºæ–¹å·®çš„ç‰¹å¾é€‰æ‹©\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "    variance_selector = VarianceThreshold(threshold=0.01)\n",
    "    X_variance = variance_selector.fit_transform(X_sample)\n",
    "    \n",
    "    # 2. åŸºäºFç»Ÿè®¡é‡çš„ç‰¹å¾é€‰æ‹©\n",
    "    f_selector = SelectKBest(f_classif, k=min(500, X_variance.shape[1]))\n",
    "    X_f_selected = f_selector.fit_transform(X_variance, y_sample)\n",
    "    \n",
    "    # 3. åŸºäºäº’ä¿¡æ¯çš„ç‰¹å¾é€‰æ‹©\n",
    "    mi_selector = SelectKBest(mutual_info_classif, k=min(300, X_f_selected.shape[1]))\n",
    "    X_mi_selected = mi_selector.fit_transform(X_f_selected, y_sample)\n",
    "    \n",
    "    # 4. åŸºäºéšæœºæ£®æ—çš„ç‰¹å¾é‡è¦æ€§\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_mi_selected, y_sample)\n",
    "    \n",
    "    feature_importances = rf.feature_importances_\n",
    "    \n",
    "    print(f\"ç‰¹å¾é€‰æ‹©ç»“æœ:\")\n",
    "    print(f\"  - åŸå§‹ç‰¹å¾æ•°: {all_features_scaled.shape[1]}\")\n",
    "    print(f\"  - æ–¹å·®è¿‡æ»¤å: {X_variance.shape[1]}\")\n",
    "    print(f\"  - Fç»Ÿè®¡é‡é€‰æ‹©å: {X_f_selected.shape[1]}\")\n",
    "    print(f\"  - äº’ä¿¡æ¯é€‰æ‹©å: {X_mi_selected.shape[1]}\")\n",
    "    \n",
    "else:\n",
    "    print(\"æœªæä¾›è®­ç»ƒæ ·æœ¬ï¼Œè¿›è¡Œæ— ç›‘ç£ç‰¹å¾é€‰æ‹©...\")\n",
    "    \n",
    "    # æ— ç›‘ç£ç‰¹å¾é€‰æ‹©\n",
    "    # 1. åŸºäºæ–¹å·®çš„ç‰¹å¾é€‰æ‹©\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "    variance_selector = VarianceThreshold(threshold=0.01)\n",
    "    selected_features = variance_selector.fit_transform(all_features_scaled)\n",
    "    \n",
    "    print(f\"æ— ç›‘ç£ç‰¹å¾é€‰æ‹©ç»“æœ:\")\n",
    "    print(f\"  - åŸå§‹ç‰¹å¾æ•°: {all_features_scaled.shape[1]}\")\n",
    "    print(f\"  - æ–¹å·®è¿‡æ»¤å: {selected_features.shape[1]}\")\n",
    "    \n",
    "    feature_importances = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰\n",
    "if feature_importances is not None:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # ç‰¹å¾é‡è¦æ€§åˆ†å¸ƒ\n",
    "    ax1.hist(feature_importances, bins=50, alpha=0.7, color='skyblue')\n",
    "    ax1.set_title('ç‰¹å¾é‡è¦æ€§åˆ†å¸ƒ')\n",
    "    ax1.set_xlabel('é‡è¦æ€§å¾—åˆ†')\n",
    "    ax1.set_ylabel('é¢‘æ¬¡')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Top 20 é‡è¦ç‰¹å¾\n",
    "    top_indices = np.argsort(feature_importances)[-20:]\n",
    "    top_importances = feature_importances[top_indices]\n",
    "    \n",
    "    ax2.barh(range(20), top_importances, color='lightcoral')\n",
    "    ax2.set_title('Top 20 é‡è¦ç‰¹å¾')\n",
    "    ax2.set_xlabel('é‡è¦æ€§å¾—åˆ†')\n",
    "    ax2.set_ylabel('ç‰¹å¾æ’å')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # æ‰“å°æœ€é‡è¦çš„ç‰¹å¾\n",
    "    print(\"\\nTop 10 æœ€é‡è¦ç‰¹å¾:\")\n",
    "    for i, idx in enumerate(top_indices[-10:]):\n",
    "        print(f\"{i+1:2d}. ç‰¹å¾ {idx:3d}: {feature_importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. é™ç»´åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸»æˆåˆ†åˆ†æ (PCA)\n",
    "print(\"å¼€å§‹é™ç»´åˆ†æ...\")\n",
    "\n",
    "# PCAåˆ†æ\n",
    "pca_full = PCA()\n",
    "pca_features = pca_full.fit_transform(all_features_scaled)\n",
    "\n",
    "# è®¡ç®—ç´¯ç§¯è§£é‡Šæ–¹å·®\n",
    "cumsum_var_ratio = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# æ‰¾åˆ°è§£é‡Š95%æ–¹å·®æ‰€éœ€çš„ä¸»æˆåˆ†æ•°\n",
    "n_components_95 = np.argmax(cumsum_var_ratio >= 0.95) + 1\n",
    "n_components_99 = np.argmax(cumsum_var_ratio >= 0.99) + 1\n",
    "\n",
    "print(f\"PCAåˆ†æç»“æœ:\")\n",
    "print(f\"  - è§£é‡Š95%æ–¹å·®éœ€è¦: {n_components_95} ä¸ªä¸»æˆåˆ†\")\n",
    "print(f\"  - è§£é‡Š99%æ–¹å·®éœ€è¦: {n_components_99} ä¸ªä¸»æˆåˆ†\")\n",
    "print(f\"  - å‰10ä¸ªä¸»æˆåˆ†è§£é‡Šæ–¹å·®æ¯”: {pca_full.explained_variance_ratio_[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–é™ç»´ç»“æœ\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. è§£é‡Šæ–¹å·®æ¯”\n",
    "axes[0, 0].plot(range(1, min(51, len(pca_full.explained_variance_ratio_) + 1)), \n",
    "                pca_full.explained_variance_ratio_[:50], 'bo-', markersize=3)\n",
    "axes[0, 0].set_title('ä¸»æˆåˆ†è§£é‡Šæ–¹å·®æ¯”')\n",
    "axes[0, 0].set_xlabel('ä¸»æˆåˆ†')\n",
    "axes[0, 0].set_ylabel('è§£é‡Šæ–¹å·®æ¯”')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. ç´¯ç§¯è§£é‡Šæ–¹å·®æ¯”\n",
    "axes[0, 1].plot(range(1, min(101, len(cumsum_var_ratio) + 1)), \n",
    "                cumsum_var_ratio[:100], 'ro-', markersize=2)\n",
    "axes[0, 1].axhline(y=0.95, color='g', linestyle='--', label='95%')\n",
    "axes[0, 1].axhline(y=0.99, color='b', linestyle='--', label='99%')\n",
    "axes[0, 1].set_title('ç´¯ç§¯è§£é‡Šæ–¹å·®æ¯”')\n",
    "axes[0, 1].set_xlabel('ä¸»æˆåˆ†æ•°é‡')\n",
    "axes[0, 1].set_ylabel('ç´¯ç§¯è§£é‡Šæ–¹å·®æ¯”')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3-6. å‰4ä¸ªä¸»æˆåˆ†çš„ç©ºé—´åˆ†å¸ƒ\n",
    "for i in range(4):\n",
    "    pc_image = pca_features[:, i].reshape(h, w)\n",
    "    im = axes[i//2 + (0 if i < 2 else 1), (i%2) + (2 if i < 2 else 0)].imshow(\n",
    "        pc_image, cmap='RdBu_r'\n",
    "    )\n",
    "    axes[i//2 + (0 if i < 2 else 1), (i%2) + (2 if i < 2 else 0)].set_title(\n",
    "        f'PC{i+1} ({pca_full.explained_variance_ratio_[i]:.1%})'\n",
    "    )\n",
    "    axes[i//2 + (0 if i < 2 else 1), (i%2) + (2 if i < 2 else 0)].axis('off')\n",
    "    plt.colorbar(im, ax=axes[i//2 + (0 if i < 2 else 1), (i%2) + (2 if i < 2 else 0)], \n",
    "                 fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å…¶ä»–é™ç»´æ–¹æ³•æ¯”è¾ƒ\n",
    "print(\"æ¯”è¾ƒä¸åŒé™ç»´æ–¹æ³•...\")\n",
    "\n",
    "# é€‰æ‹©å­é›†è¿›è¡Œå¿«é€Ÿè®¡ç®—\n",
    "subset_size = min(5000, all_features_scaled.shape[0])\n",
    "subset_indices = np.random.choice(all_features_scaled.shape[0], subset_size, replace=False)\n",
    "X_subset = all_features_scaled[subset_indices]\n",
    "\n",
    "# 1. ICA\n",
    "ica = FastICA(n_components=10, random_state=42)\n",
    "ica_features = ica.fit_transform(X_subset)\n",
    "\n",
    "# 2. NMF (éè´ŸçŸ©é˜µåˆ†è§£)\n",
    "# ç¡®ä¿æ•°æ®ä¸ºéè´Ÿ\n",
    "X_subset_positive = X_subset - X_subset.min() + 1e-10\n",
    "nmf = NMF(n_components=10, random_state=42)\n",
    "nmf_features = nmf.fit_transform(X_subset_positive)\n",
    "\n",
    "# 3. t-SNE (ä»…ç”¨äºå¯è§†åŒ–)\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_features = tsne.fit_transform(X_subset[:1000])  # ä»…ä½¿ç”¨1000ä¸ªæ ·æœ¬\n",
    "\n",
    "print(f\"é™ç»´æ–¹æ³•æ¯”è¾ƒå®Œæˆ\")\n",
    "print(f\"  - PCA: {pca_features[:subset_size].shape}\")\n",
    "print(f\"  - ICA: {ica_features.shape}\")\n",
    "print(f\"  - NMF: {nmf_features.shape}\")\n",
    "print(f\"  - t-SNE: {tsne_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ä¸åŒé™ç»´æ–¹æ³•çš„ç»“æœ\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# PCAå‰ä¸¤ä¸ªä¸»æˆåˆ†\n",
    "axes[0, 0].scatter(pca_features[subset_indices, 0], pca_features[subset_indices, 1], \n",
    "                   alpha=0.6, s=1)\n",
    "axes[0, 0].set_title('PCA (PC1 vs PC2)')\n",
    "axes[0, 0].set_xlabel('PC1')\n",
    "axes[0, 0].set_ylabel('PC2')\n",
    "\n",
    "# ICAå‰ä¸¤ä¸ªæˆåˆ†\n",
    "axes[0, 1].scatter(ica_features[:, 0], ica_features[:, 1], alpha=0.6, s=1)\n",
    "axes[0, 1].set_title('ICA (IC1 vs IC2)')\n",
    "axes[0, 1].set_xlabel('IC1')\n",
    "axes[0, 1].set_ylabel('IC2')\n",
    "\n",
    "# NMFå‰ä¸¤ä¸ªæˆåˆ†\n",
    "axes[1, 0].scatter(nmf_features[:, 0], nmf_features[:, 1], alpha=0.6, s=1)\n",
    "axes[1, 0].set_title('NMF (Component 1 vs 2)')\n",
    "axes[1, 0].set_xlabel('Component 1')\n",
    "axes[1, 0].set_ylabel('Component 2')\n",
    "\n",
    "# t-SNE\n",
    "axes[1, 1].scatter(tsne_features[:, 0], tsne_features[:, 1], alpha=0.6, s=1)\n",
    "axes[1, 1].set_title('t-SNE')\n",
    "axes[1, 1].set_xlabel('t-SNE 1')\n",
    "axes[1, 1].set_ylabel('t-SNE 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ä¿å­˜ç‰¹å¾å·¥ç¨‹ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜ç‰¹å¾å·¥ç¨‹ç»“æœ\n",
    "print(\"ä¿å­˜ç‰¹å¾å·¥ç¨‹ç»“æœ...\")\n",
    "\n",
    "# 1. ä¿å­˜å®Œæ•´ç‰¹å¾é›†\n",
    "np.save(output_dir / 'all_features.npy', all_features_scaled)\n",
    "np.save(output_dir / 'feature_names.npy', np.array(feature_names_list))\n",
    "\n",
    "# 2. ä¿å­˜PCAç»“æœ\n",
    "np.save(output_dir / 'pca_features.npy', pca_features)\n",
    "np.save(output_dir / 'pca_explained_variance_ratio.npy', pca_full.explained_variance_ratio_)\n",
    "\n",
    "# 3. ä¿å­˜é™ç»´åˆ°95%æ–¹å·®çš„ä¸»æˆåˆ†\n",
    "pca_95_features = pca_features[:, :n_components_95]\n",
    "np.save(output_dir / 'pca_95_features.npy', pca_95_features)\n",
    "\n",
    "# 4. ä¿å­˜å„ç±»ç‰¹å¾\n",
    "np.save(output_dir / 'vegetation_indices.npy', vegetation_features)\n",
    "np.save(output_dir / 'texture_features.npy', texture_features)\n",
    "np.save(output_dir / 'spatial_features.npy', spatial_features)\n",
    "\n",
    "# 5. ä¿å­˜é¢„å¤„ç†å™¨\n",
    "import joblib\n",
    "joblib.dump(scaler, output_dir / 'feature_scaler.pkl')\n",
    "joblib.dump(pca_full, output_dir / 'pca_model.pkl')\n",
    "\n",
    "if feature_importances is not None:\n",
    "    np.save(output_dir / 'feature_importances.npy', feature_importances)\n",
    "\n",
    "print(f\"ç‰¹å¾å·¥ç¨‹ç»“æœå·²ä¿å­˜åˆ°: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆç‰¹å¾å·¥ç¨‹æŠ¥å‘Š\n",
    "feature_report = {\n",
    "    'æ•°æ®æ¦‚å†µ': {\n",
    "        'åŸå§‹æ•°æ®å½¢çŠ¶': str(hyperspectral_data.shape),\n",
    "        'æ€»åƒç´ æ•°': int(h * w),\n",
    "        'åŸå§‹æ³¢æ®µæ•°': int(hyperspectral_data.shape[2]),\n",
    "        'æ³¢é•¿èŒƒå›´': f'{wavelengths[0]:.1f} - {wavelengths[-1]:.1f} nm'\n",
    "    },\n",
    "    'ç‰¹å¾ç»Ÿè®¡': {\n",
    "        'æ€»ç‰¹å¾æ•°': int(all_features_scaled.shape[1]),\n",
    "        'åŸå§‹å…‰è°±ç‰¹å¾': int(original_features.shape[1]),\n",
    "        'æ¤è¢«æŒ‡æ•°æ•°é‡': int(vegetation_features_2d.shape[1]),\n",
    "        'çº¹ç†ç‰¹å¾æ•°é‡': int(texture_features_2d.shape[1]),\n",
    "        'ç©ºé—´ç‰¹å¾æ•°é‡': int(spatial_features_2d.shape[1])\n",
    "    },\n",
    "    'é™ç»´åˆ†æ': {\n",
    "        '95%æ–¹å·®ä¸»æˆåˆ†æ•°': int(n_components_95),\n",
    "        '99%æ–¹å·®ä¸»æˆåˆ†æ•°': int(n_components_99),\n",
    "        'å‰5ä¸ªPCè§£é‡Šæ–¹å·®': [float(x) for x in pca_full.explained_variance_ratio_[:5]],\n",
    "        'ç»´åº¦å‹ç¼©æ¯”': f'{n_components_95}/{all_features_scaled.shape[1]} ({n_components_95/all_features_scaled.shape[1]:.1%})'\n",
    "    },\n",
    "    'å¤„ç†è®¾ç½®': {\n",
    "        'æ ‡å‡†åŒ–æ–¹æ³•': 'StandardScaler',\n",
    "        'çº¹ç†åˆ†ææ³¢æ®µ': texture_bands,\n",
    "        'ç©ºé—´ç‰¹å¾æ–¹æ³•': spatial_extractor.methods if hasattr(spatial_extractor, 'methods') else 'Unknown',\n",
    "        'æ¤è¢«æŒ‡æ•°ç±»å‹': len(vegetation_indices.get_index_names())\n",
    "    }\n",
    "}\n",
    "\n",
    "# ä¿å­˜æŠ¥å‘Š\n",
    "import json\n",
    "with open(output_dir / 'feature_engineering_report.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(feature_report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# æ‰“å°æŠ¥å‘Š\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ¹¿åœ°é«˜å…‰è°±ç‰¹å¾å·¥ç¨‹æŠ¥å‘Š\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for section, items in feature_report.items():\n",
    "    print(f\"\\n{section}:\")\n",
    "    for key, value in items.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nç‰¹å¾å·¥ç¨‹æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_dir / 'feature_engineering_report.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "æœ¬notebookå®Œæˆäº†æ¹¿åœ°é«˜å…‰è°±æ•°æ®çš„å…¨é¢ç‰¹å¾å·¥ç¨‹:\n",
    "\n",
    "### ğŸ” ä¸»è¦æˆæœ:\n",
    "1. **å¤šç»´ç‰¹å¾æå–**: æˆåŠŸæå–äº†å…‰è°±ã€æ¤è¢«ã€çº¹ç†å’Œç©ºé—´å››å¤§ç±»ç‰¹å¾\n",
    "2. **ç‰¹å¾èåˆ**: æ„å»ºäº†ç»¼åˆç‰¹å¾é›†ï¼Œä¸ºåˆ†ç±»åˆ†ææä¾›ä¸°å¯Œä¿¡æ¯\n",
    "3. **é™ç»´ä¼˜åŒ–**: é€šè¿‡PCAåˆ†æå®ç°äº†æœ‰æ•ˆçš„ç»´åº¦å‹ç¼©\n",
    "4. **è´¨é‡è¯„ä¼°**: å…¨é¢è¯„ä¼°äº†ç‰¹å¾çš„ç»Ÿè®¡ç‰¹æ€§å’Œé‡è¦æ€§\n",
    "\n",
    "### ğŸ“Š å…³é”®æŒ‡æ ‡:\n",
    "- æ€»ç‰¹å¾æ•°é‡: {}\n",
    "- 95%æ–¹å·®ä¿ç•™çš„ä¸»æˆåˆ†æ•°: {}\n",
    "- ç»´åº¦å‹ç¼©æ¯”: {:.1%}\n",
    "- ç‰¹å¾è´¨é‡: é«˜è´¨é‡ï¼Œå·²æ ‡å‡†åŒ–å¤„ç†\n",
    "\n",
    "### ğŸ¯ ä¸‹ä¸€æ­¥å·¥ä½œ:\n",
    "1. ä½¿ç”¨æå–çš„ç‰¹å¾è¿›è¡Œæ¨¡å‹è®­ç»ƒ\n",
    "2. æ¯”è¾ƒä¸åŒç‰¹å¾ç»„åˆçš„åˆ†ç±»æ•ˆæœ\n",
    "3. ä¼˜åŒ–ç‰¹å¾é€‰æ‹©ç­–ç•¥\n",
    "4. è¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„ç«¯åˆ°ç«¯è®­ç»ƒ\n",
    "\n",
    "ç‰¹å¾å·¥ç¨‹æ˜¯æˆåŠŸåˆ†ç±»çš„åŸºç¡€ï¼Œæœ¬é˜¶æ®µä¸ºåç»­çš„æ¨¡å‹è®­ç»ƒå’Œåˆ†æå¥ å®šäº†åšå®åŸºç¡€ã€‚\n",
    "\".format(\n",
    "    all_features_scaled.shape[1],\n",
    "    n_components_95, \n",
    "    n_components_95/all_features_scaled.shape[1]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n",
   "language": "python",\n",
   "name": "python3"\n",
  },\n",
  "language_info": {\n",
   "codemirror_mode": {\n",
    "name": "ipython",\n",
    "version": 3\n",
   },\n",
   "file_extension": ".py",\n",
   "mimetype": "text/x-python",\n",
   "name": "python",\n",
   "nbconvert_exporter": "python",\n",
   "pygments_lexer": "ipython3",\n",
   "version": "3.9.0"\n",
  }\n },\n "nbformat": 4,\n "nbformat_minor": 4\n}
  