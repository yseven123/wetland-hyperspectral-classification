# æ¹¿åœ°é«˜å…‰è°±åˆ†ç±»ç³»ç»ŸAPIæ–‡æ¡£
## Wetland Hyperspectral Classification System - API Reference

### ğŸ“‹ ç›®å½•

1. [æ ¸å¿ƒæ¨¡å—](#æ ¸å¿ƒæ¨¡å—)
2. [æ•°æ®æ¨¡å—](#æ•°æ®æ¨¡å—)
3. [é¢„å¤„ç†æ¨¡å—](#é¢„å¤„ç†æ¨¡å—)
4. [ç‰¹å¾æå–æ¨¡å—](#ç‰¹å¾æå–æ¨¡å—)
5. [åˆ†ç±»æ¨¡å—](#åˆ†ç±»æ¨¡å—)
6. [åå¤„ç†æ¨¡å—](#åå¤„ç†æ¨¡å—)
7. [æ™¯è§‚åˆ†ææ¨¡å—](#æ™¯è§‚åˆ†ææ¨¡å—)
8. [è¯„ä¼°æ¨¡å—](#è¯„ä¼°æ¨¡å—)
9. [å·¥å…·æ¨¡å—](#å·¥å…·æ¨¡å—)
10. [é…ç½®æ¨¡å—](#é…ç½®æ¨¡å—)

---

## ğŸ¯ æ ¸å¿ƒæ¨¡å—

### Pipeline

å®Œæ•´çš„å¤„ç†æµæ°´çº¿ï¼Œæä¾›ä¸€ç«™å¼çš„é«˜å…‰è°±æ•°æ®åˆ†ç±»è§£å†³æ–¹æ¡ˆã€‚

```python
class Pipeline:
    """ä¸»å¤„ç†æµæ°´çº¿
    
    é›†æˆäº†æ•°æ®åŠ è½½ã€é¢„å¤„ç†ã€ç‰¹å¾æå–ã€åˆ†ç±»å’Œè¯„ä¼°çš„å®Œæ•´æµç¨‹ã€‚
    """
    
    def __init__(self, config: Config):
        """
        åˆå§‹åŒ–æµæ°´çº¿
        
        Args:
            config (Config): é…ç½®å¯¹è±¡
        """
        pass
    
    def run(self, 
            input_data: str, 
            ground_truth: Optional[str] = None,
            output_dir: str = 'output/') -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„åˆ†ç±»æµç¨‹
        
        Args:
            input_data: è¾“å…¥é«˜å…‰è°±æ•°æ®è·¯å¾„
            ground_truth: å¯é€‰çš„åœ°é¢çœŸå®æ•°æ®è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            åŒ…å«åˆ†ç±»ç»“æœå’Œè¯„ä¼°æŒ‡æ ‡çš„å­—å…¸
            
        Example:
            >>> pipeline = Pipeline(config)
            >>> results = pipeline.run('data/scene.tif', 'data/labels.shp')
            >>> print(f"Accuracy: {results['accuracy']:.3f}")
        """
        pass
    
    def run_demo(self, demo_path: str = 'data/samples/demo_scene/') -> Dict[str, Any]:
        """
        è¿è¡Œæ¼”ç¤ºæµç¨‹
        
        Args:
            demo_path: æ¼”ç¤ºæ•°æ®è·¯å¾„
            
        Returns:
            æ¼”ç¤ºç»“æœå­—å…¸
        """
        pass
    
    @classmethod
    def from_config(cls, config_path: str) -> 'Pipeline':
        """
        ä»é…ç½®æ–‡ä»¶åˆ›å»ºæµæ°´çº¿
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            é…ç½®å¥½çš„æµæ°´çº¿å®ä¾‹
        """
        pass
```

---

## ğŸ“ æ•°æ®æ¨¡å—

### DataLoader

æ•°æ®åŠ è½½å™¨ï¼Œæ”¯æŒå¤šç§æ ¼å¼çš„é«˜å…‰è°±æ•°æ®å’Œåœ°é¢çœŸå®æ•°æ®ã€‚

```python
class DataLoader:
    """æ•°æ®åŠ è½½å™¨
    
    æ”¯æŒGeoTIFF, ENVI, HDF5ç­‰å¤šç§æ ¼å¼çš„é«˜å…‰è°±æ•°æ®åŠ è½½ï¼Œ
    ä»¥åŠShapefile, GeoJSONç­‰åœ°é¢çœŸå®æ•°æ®æ ¼å¼ã€‚
    """
    
    def __init__(self, config: Optional[Config] = None):
        """
        åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        
        Args:
            config: å¯é€‰çš„é…ç½®å¯¹è±¡
        """
        pass
    
    def load_hyperspectral(self, path: str) -> Tuple[np.ndarray, Dict]:
        """
        åŠ è½½é«˜å…‰è°±æ•°æ®
        
        Args:
            path: æ•°æ®æ–‡ä»¶è·¯å¾„
            
        Returns:
            (data, metadata): æ•°æ®æ•°ç»„å’Œå…ƒæ•°æ®å­—å…¸
            data shape: (height, width, bands)
            
        Raises:
            DataLoadError: å½“æ•°æ®åŠ è½½å¤±è´¥æ—¶
            
        Example:
            >>> loader = DataLoader()
            >>> data, meta = loader.load_hyperspectral('scene.tif')
            >>> print(f"Data shape: {data.shape}")
        """
        pass
    
    def load_ground_truth(self, path: str) -> np.ndarray:
        """
        åŠ è½½åœ°é¢çœŸå®æ ‡ç­¾
        
        Args:
            path: æ ‡ç­¾æ–‡ä»¶è·¯å¾„ï¼ˆ.shp, .geojson, .csvï¼‰
            
        Returns:
            æ ‡ç­¾æ•°ç»„ï¼Œshape: (height, width)
            
        Example:
            >>> labels = loader.load_ground_truth('labels.shp')
            >>> unique_classes = np.unique(labels[labels > 0])
        """
        pass
    
    def load_scene_data(self, scene_dir: str) -> Dict[str, Any]:
        """
        åŠ è½½å®Œæ•´åœºæ™¯æ•°æ®
        
        Args:
            scene_dir: åœºæ™¯æ•°æ®ç›®å½•
            
        Returns:
            åŒ…å«é«˜å…‰è°±æ•°æ®ã€æ ‡ç­¾ã€å…ƒæ•°æ®çš„å­—å…¸
        """
        pass
```

### DataValidator

æ•°æ®éªŒè¯å™¨ï¼Œç¡®ä¿æ•°æ®è´¨é‡å’Œæ ¼å¼æ­£ç¡®æ€§ã€‚

```python
class DataValidator:
    """æ•°æ®éªŒè¯å™¨"""
    
    def validate_hyperspectral(self, data: np.ndarray) -> ValidationResult:
        """
        éªŒè¯é«˜å…‰è°±æ•°æ®
        
        Args:
            data: é«˜å…‰è°±æ•°æ®æ•°ç»„
            
        Returns:
            éªŒè¯ç»“æœå¯¹è±¡
            
        Example:
            >>> validator = DataValidator()
            >>> result = validator.validate_hyperspectral(data)
            >>> if not result.is_valid:
            ...     print(result.errors)
        """
        pass
    
    def validate_labels(self, labels: np.ndarray) -> ValidationResult:
        """
        éªŒè¯æ ‡ç­¾æ•°æ®
        
        Args:
            labels: æ ‡ç­¾æ•°ç»„
            
        Returns:
            éªŒè¯ç»“æœå¯¹è±¡
        """
        pass
```

---

## ğŸ”§ é¢„å¤„ç†æ¨¡å—

### Preprocessor

æ•°æ®é¢„å¤„ç†å™¨ï¼Œæä¾›è¾å°„å®šæ ‡ã€å¤§æ°”æ ¡æ­£ã€å‡ ä½•æ ¡æ­£ç­‰åŠŸèƒ½ã€‚

```python
class Preprocessor:
    """æ•°æ®é¢„å¤„ç†å™¨
    
    æä¾›å®Œæ•´çš„é«˜å…‰è°±æ•°æ®é¢„å¤„ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬è¾å°„å®šæ ‡ã€
    å¤§æ°”æ ¡æ­£ã€å‡ ä½•æ ¡æ­£å’Œå™ªå£°å»é™¤ã€‚
    """
    
    def __init__(self, config: Optional[PreprocessingConfig] = None):
        """
        åˆå§‹åŒ–é¢„å¤„ç†å™¨
        
        Args:
            config: é¢„å¤„ç†é…ç½®
        """
        pass
    
    def process_all(self, data: np.ndarray, 
                   steps: List[str] = None) -> np.ndarray:
        """
        æ‰§è¡Œå®Œæ•´é¢„å¤„ç†æµç¨‹
        
        Args:
            data: åŸå§‹é«˜å…‰è°±æ•°æ®
            steps: é¢„å¤„ç†æ­¥éª¤åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºå…¨éƒ¨æ­¥éª¤
            
        Returns:
            é¢„å¤„ç†åçš„æ•°æ®
            
        Example:
            >>> preprocessor = Preprocessor()
            >>> processed = preprocessor.process_all(
            ...     raw_data, 
            ...     steps=['radiometric', 'atmospheric', 'geometric']
            ... )
        """
        pass
    
    def radiometric_calibration(self, data: np.ndarray) -> np.ndarray:
        """
        è¾å°„å®šæ ‡
        
        å°†DNå€¼è½¬æ¢ä¸ºè¾å°„äº®åº¦å€¼
        
        Args:
            data: åŸå§‹DNå€¼æ•°æ®
            
        Returns:
            è¾å°„å®šæ ‡åçš„æ•°æ®
        """
        pass
    
    def atmospheric_correction(self, data: np.ndarray, 
                             method: str = 'FLAASH') -> np.ndarray:
        """
        å¤§æ°”æ ¡æ­£
        
        Args:
            data: è¾å°„å®šæ ‡åçš„æ•°æ®
            method: å¤§æ°”æ ¡æ­£æ–¹æ³• ('FLAASH', 'QUAC', 'ATCOR')
            
        Returns:
            å¤§æ°”æ ¡æ­£åçš„åå°„ç‡æ•°æ®
        """
        pass
    
    def geometric_correction(self, data: np.ndarray) -> np.ndarray:
        """
        å‡ ä½•æ ¡æ­£
        
        Args:
            data: å¾…æ ¡æ­£çš„æ•°æ®
            
        Returns:
            å‡ ä½•æ ¡æ­£åçš„æ•°æ®
        """
        pass
    
    def noise_reduction(self, data: np.ndarray, 
                       method: str = 'MNF') -> np.ndarray:
        """
        å™ªå£°å»é™¤
        
        Args:
            data: å¾…å»å™ªçš„æ•°æ®
            method: å»å™ªæ–¹æ³• ('MNF', 'PCA', 'Wavelet')
            
        Returns:
            å»å™ªåçš„æ•°æ®
        """
        pass
```

---

## ğŸ¨ ç‰¹å¾æå–æ¨¡å—

### FeatureExtractor

ç‰¹å¾æå–å™¨ï¼Œæ”¯æŒå…‰è°±ç‰¹å¾ã€æ¤è¢«æŒ‡æ•°ã€çº¹ç†ç‰¹å¾ç­‰å¤šç§ç‰¹å¾ã€‚

```python
class FeatureExtractor:
    """ç‰¹å¾æå–å™¨
    
    æä¾›å…‰è°±ç‰¹å¾ã€æ¤è¢«æŒ‡æ•°ã€çº¹ç†ç‰¹å¾ã€ç©ºé—´ç‰¹å¾ç­‰
    å¤šç§ç‰¹å¾æå–åŠŸèƒ½ã€‚
    """
    
    def __init__(self, config: Optional[FeatureConfig] = None):
        """
        åˆå§‹åŒ–ç‰¹å¾æå–å™¨
        
        Args:
            config: ç‰¹å¾æå–é…ç½®
        """
        pass
    
    def extract_all(self, data: np.ndarray) -> Dict[str, np.ndarray]:
        """
        æå–æ‰€æœ‰ç‰¹å¾
        
        Args:
            data: é¢„å¤„ç†åçš„é«˜å…‰è°±æ•°æ®
            
        Returns:
            ç‰¹å¾å­—å…¸ï¼Œé”®ä¸ºç‰¹å¾ç±»å‹ï¼Œå€¼ä¸ºç‰¹å¾æ•°ç»„
            
        Example:
            >>> extractor = FeatureExtractor()
            >>> features = extractor.extract_all(processed_data)
            >>> print(list(features.keys()))
            ['spectral', 'vegetation_indices', 'texture', 'spatial']
        """
        pass
    
    def extract_spectral_features(self, data: np.ndarray) -> np.ndarray:
        """
        æå–å…‰è°±ç‰¹å¾
        
        Args:
            data: é«˜å…‰è°±æ•°æ® (H, W, Bands)
            
        Returns:
            å…‰è°±ç‰¹å¾æ•°ç»„ (H, W, Features)
            
        Example:
            >>> spectral_features = extractor.extract_spectral_features(data)
            >>> print(f"Spectral features shape: {spectral_features.shape}")
        """
        pass
    
    def extract_vegetation_indices(self, data: np.ndarray) -> Dict[str, np.ndarray]:
        """
        æå–æ¤è¢«æŒ‡æ•°
        
        Args:
            data: é«˜å…‰è°±æ•°æ®
            
        Returns:
            æ¤è¢«æŒ‡æ•°å­—å…¸
            
        Available indices:
            - NDVI: å½’ä¸€åŒ–å·®å¼‚æ¤è¢«æŒ‡æ•°
            - NDWI: å½’ä¸€åŒ–å·®å¼‚æ°´åˆ†æŒ‡æ•°
            - EVI: å¢å¼ºæ¤è¢«æŒ‡æ•°
            - SAVI: åœŸå£¤è°ƒèŠ‚æ¤è¢«æŒ‡æ•°
            - PRI: å…‰åŒ–å­¦åå°„æŒ‡æ•°
            - GNDVI: ç»¿åº¦å½’ä¸€åŒ–å·®å¼‚æ¤è¢«æŒ‡æ•°
            
        Example:
            >>> indices = extractor.extract_vegetation_indices(data)
            >>> ndvi = indices['NDVI']
            >>> ndwi = indices['NDWI']
        """
        pass
    
    def extract_texture_features(self, data: np.ndarray, 
                               window_size: int = 5) -> np.ndarray:
        """
        æå–çº¹ç†ç‰¹å¾
        
        Args:
            data: è¾“å…¥æ•°æ®
            window_size: çº¹ç†è®¡ç®—çª—å£å¤§å°
            
        Returns:
            çº¹ç†ç‰¹å¾æ•°ç»„
            
        Features:
            - å¯¹æ¯”åº¦ (Contrast)
            - ç›¸å…³æ€§ (Correlation) 
            - èƒ½é‡ (Energy)
            - ç†µ (Entropy)
            - å‡åŒ€æ€§ (Homogeneity)
            - æ–¹å·® (Variance)
        """
        pass
    
    def extract_spatial_features(self, data: np.ndarray) -> np.ndarray:
        """
        æå–ç©ºé—´ç‰¹å¾
        
        Args:
            data: è¾“å…¥æ•°æ®
            
        Returns:
            ç©ºé—´ç‰¹å¾æ•°ç»„
            
        Features:
            - è¾¹ç¼˜ç‰¹å¾
            - å½¢æ€å­¦ç‰¹å¾
            - å±€éƒ¨äºŒå€¼æ¨¡å¼
        """
        pass
```

### SpectralIndices

ä¸“é—¨çš„å…‰è°±æŒ‡æ•°è®¡ç®—ç±»ã€‚

```python
class SpectralIndices:
    """å…‰è°±æŒ‡æ•°è®¡ç®—å™¨"""
    
    @staticmethod
    def ndvi(nir: np.ndarray, red: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—NDVI
        
        Args:
            nir: è¿‘çº¢å¤–æ³¢æ®µ
            red: çº¢å…‰æ³¢æ®µ
            
        Returns:
            NDVIæ•°ç»„
            
        Formula:
            NDVI = (NIR - Red) / (NIR + Red)
        """
        return (nir - red) / (nir + red + 1e-8)
    
    @staticmethod
    def ndwi(nir: np.ndarray, swir: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—NDWI
        
        Args:
            nir: è¿‘çº¢å¤–æ³¢æ®µ
            swir: çŸ­æ³¢çº¢å¤–æ³¢æ®µ
            
        Returns:
            NDWIæ•°ç»„
            
        Formula:
            NDWI = (NIR - SWIR) / (NIR + SWIR)
        """
        return (nir - swir) / (nir + swir + 1e-8)
    
    @staticmethod
    def evi(nir: np.ndarray, red: np.ndarray, blue: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—EVI
        
        Args:
            nir: è¿‘çº¢å¤–æ³¢æ®µ
            red: çº¢å…‰æ³¢æ®µ
            blue: è“å…‰æ³¢æ®µ
            
        Returns:
            EVIæ•°ç»„
            
        Formula:
            EVI = 2.5 * (NIR - Red) / (NIR + 6 * Red - 7.5 * Blue + 1)
        """
        return 2.5 * (nir - red) / (nir + 6 * red - 7.5 * blue + 1 + 1e-8)
```

---

## ğŸ¤– åˆ†ç±»æ¨¡å—

### Classifier

é€šç”¨åˆ†ç±»å™¨æ¥å£ï¼Œæ”¯æŒå¤šç§æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚

```python
class Classifier:
    """é€šç”¨åˆ†ç±»å™¨
    
    æ”¯æŒSVMã€Random Forestã€XGBoostã€3D-CNNã€HybridSNç­‰å¤šç§åˆ†ç±»ç®—æ³•ã€‚
    """
    
    def __init__(self, model_type: str, **kwargs):
        """
        åˆå§‹åŒ–åˆ†ç±»å™¨
        
        Args:
            model_type: æ¨¡å‹ç±»å‹
                - 'svm': æ”¯æŒå‘é‡æœº
                - 'random_forest': éšæœºæ£®æ—
                - 'xgboost': æç«¯æ¢¯åº¦æå‡
                - 'cnn_3d': 3Då·ç§¯ç¥ç»ç½‘ç»œ
                - 'hybrid_cnn': æ··åˆå·ç§¯ç½‘ç»œ
                - 'transformer': Vision Transformer
            **kwargs: æ¨¡å‹ç‰¹å®šå‚æ•°
            
        Example:
            >>> # SVMåˆ†ç±»å™¨
            >>> svm_clf = Classifier('svm', C=1.0, kernel='rbf')
            >>> 
            >>> # æ·±åº¦å­¦ä¹ åˆ†ç±»å™¨
            >>> cnn_clf = Classifier('cnn_3d', learning_rate=0.001, epochs=100)
        """
        pass
    
    def fit(self, X: np.ndarray, y: np.ndarray, 
            X_val: Optional[np.ndarray] = None,
            y_val: Optional[np.ndarray] = None) -> 'Classifier':
        """
        è®­ç»ƒåˆ†ç±»å™¨
        
        Args:
            X: è®­ç»ƒç‰¹å¾ (N_samples, N_features) æˆ– (N_samples, H, W, Bands)
            y: è®­ç»ƒæ ‡ç­¾ (N_samples,)
            X_val: å¯é€‰çš„éªŒè¯ç‰¹å¾
            y_val: å¯é€‰çš„éªŒè¯æ ‡ç­¾
            
        Returns:
            è®­ç»ƒå¥½çš„åˆ†ç±»å™¨å®ä¾‹
            
        Example:
            >>> classifier.fit(X_train, y_train, X_val, y_val)
            >>> print("Training completed!")
        """
        pass
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        é¢„æµ‹æ ‡ç­¾
        
        Args:
            X: æµ‹è¯•ç‰¹å¾
            
        Returns:
            é¢„æµ‹æ ‡ç­¾æ•°ç»„
            
        Example:
            >>> predictions = classifier.predict(X_test)
            >>> accuracy = np.mean(predictions == y_test)
        """
        pass
    
    def predict_proba(self, X: np.ndarray) -> np.ndarray:
        """
        é¢„æµ‹ç±»åˆ«æ¦‚ç‡
        
        Args:
            X: æµ‹è¯•ç‰¹å¾
            
        Returns:
            ç±»åˆ«æ¦‚ç‡æ•°ç»„ (N_samples, N_classes)
            
        Example:
            >>> probabilities = classifier.predict_proba(X_test)
            >>> confidence = np.max(probabilities, axis=1)
        """
        pass
    
    def predict_scene(self, scene_path: str, 
                     output_path: str = None) -> np.ndarray:
        """
        é¢„æµ‹æ•´ä¸ªåœºæ™¯
        
        Args:
            scene_path: åœºæ™¯æ•°æ®è·¯å¾„
            output_path: å¯é€‰çš„è¾“å‡ºè·¯å¾„
            
        Returns:
            åœºæ™¯åˆ†ç±»ç»“æœ
            
        Example:
            >>> result = classifier.predict_scene('test_scene.tif', 'result.tif')
            >>> print(f"Classification completed. Unique classes: {np.unique(result)}")
        """
        pass
    
    def save_model(self, path: str):
        """
        ä¿å­˜æ¨¡å‹
        
        Args:
            path: ä¿å­˜è·¯å¾„
            
        Example:
            >>> classifier.save_model('models/best_model.pkl')
        """
        pass
    
    @classmethod
    def load_model(cls, path: str) -> 'Classifier':
        """
        åŠ è½½æ¨¡å‹
        
        Args:
            path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŠ è½½çš„åˆ†ç±»å™¨å®ä¾‹
            
        Example:
            >>> classifier = Classifier.load_model('models/best_model.pkl')
            >>> predictions = classifier.predict(X_test)
        """
        pass
```

### EnsembleClassifier

é›†æˆåˆ†ç±»å™¨ï¼Œç»„åˆå¤šä¸ªåŸºåˆ†ç±»å™¨æé«˜æ€§èƒ½ã€‚

```python
class EnsembleClassifier:
    """é›†æˆåˆ†ç±»å™¨
    
    é€šè¿‡ç»„åˆå¤šä¸ªåŸºåˆ†ç±»å™¨æ¥æé«˜åˆ†ç±»æ€§èƒ½å’Œé²æ£’æ€§ã€‚
    """
    
    def __init__(self, classifiers: List[Tuple[str, str]], 
                 ensemble_method: str = 'voting'):
        """
        åˆå§‹åŒ–é›†æˆåˆ†ç±»å™¨
        
        Args:
            classifiers: åŸºåˆ†ç±»å™¨åˆ—è¡¨ [(name, model_type), ...]
            ensemble_method: é›†æˆæ–¹æ³• ('voting', 'stacking', 'weighted')
            
        Example:
            >>> ensemble = EnsembleClassifier([
            ...     ('svm', 'svm'),
            ...     ('rf', 'random_forest'),
            ...     ('cnn', 'hybrid_cnn')
            ... ], ensemble_method='voting')
        """
        pass
    
    def fit(self, X: np.ndarray, y: np.ndarray):
        """
        è®­ç»ƒé›†æˆåˆ†ç±»å™¨
        
        Args:
            X: è®­ç»ƒç‰¹å¾
            y: è®­ç»ƒæ ‡ç­¾
        """
        pass
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        é›†æˆé¢„æµ‹
        
        Args:
            X: æµ‹è¯•ç‰¹å¾
            
        Returns:
            é›†æˆé¢„æµ‹ç»“æœ
        """
        pass
```

---

## ğŸ”¬ åå¤„ç†æ¨¡å—

### PostProcessor

åå¤„ç†å™¨ï¼Œæä¾›ç©ºé—´æ»¤æ³¢ã€å½¢æ€å­¦æ“ä½œç­‰åŠŸèƒ½ã€‚

```python
class PostProcessor:
    """åå¤„ç†å™¨
    
    å¯¹åˆ†ç±»ç»“æœè¿›è¡Œåå¤„ç†ï¼ŒåŒ…æ‹¬ç©ºé—´æ»¤æ³¢ã€å½¢æ€å­¦æ“ä½œã€
    ä¸€è‡´æ€§æ£€æŸ¥ç­‰ï¼Œä»¥æé«˜åˆ†ç±»ç»“æœçš„è´¨é‡ã€‚
    """
    
    def __init__(self, config: Optional[PostProcessingConfig] = None):
        """
        åˆå§‹åŒ–åå¤„ç†å™¨
        
        Args:
            config: åå¤„ç†é…ç½®
        """
        pass
    
    def spatial_filter(self, classification_map: np.ndarray,
                      filter_type: str = 'majority',
                      window_size: int = 3) -> np.ndarray:
        """
        ç©ºé—´æ»¤æ³¢
        
        Args:
            classification_map: åˆ†ç±»ç»“æœå›¾
            filter_type: æ»¤æ³¢ç±»å‹ ('majority', 'median', 'mode')
            window_size: æ»¤æ³¢çª—å£å¤§å°
            
        Returns:
            æ»¤æ³¢åçš„åˆ†ç±»å›¾
            
        Example:
            >>> processor = PostProcessor()
            >>> filtered = processor.spatial_filter(
            ...     classification_map, 
            ...     filter_type='majority', 
            ...     window_size=5
            ... )
        """
        pass
    
    def morphological_filter(self, classification_map: np.ndarray,
                           operation: str = 'opening',
                           kernel_size: int = 3) -> np.ndarray:
        """
        å½¢æ€å­¦æ»¤æ³¢
        
        Args:
            classification_map: åˆ†ç±»ç»“æœå›¾
            operation: å½¢æ€å­¦æ“ä½œ ('opening', 'closing', 'erosion', 'dilation')
            kernel_size: æ ¸å¤§å°
            
        Returns:
            å½¢æ€å­¦æ»¤æ³¢åçš„åˆ†ç±»å›¾
        """
        pass
    
    def remove_small_objects(self, classification_map: np.ndarray,
                           min_size: int = 10) -> np.ndarray:
        """
        ç§»é™¤å°å¯¹è±¡
        
        Args:
            classification_map: åˆ†ç±»ç»“æœå›¾
            min_size: æœ€å°å¯¹è±¡å¤§å°ï¼ˆåƒç´ æ•°ï¼‰
            
        Returns:
            ç§»é™¤å°å¯¹è±¡åçš„åˆ†ç±»å›¾
        """
        pass
```

---

## ğŸŒ¿ æ™¯è§‚åˆ†ææ¨¡å—

### LandscapeAnalyzer

æ™¯è§‚æ ¼å±€åˆ†æå™¨ï¼Œè®¡ç®—å„ç§æ™¯è§‚ç”Ÿæ€å­¦æŒ‡æ ‡ã€‚

```python
class LandscapeAnalyzer:
    """æ™¯è§‚æ ¼å±€åˆ†æå™¨
    
    è®¡ç®—æ™¯è§‚ç”Ÿæ€å­¦æŒ‡æ ‡ï¼ŒåŒ…æ‹¬æ–‘å—æŒ‡æ ‡ã€ç±»åˆ«æŒ‡æ ‡å’Œæ™¯è§‚æŒ‡æ ‡ã€‚
    """
    
    def __init__(self, config: Optional[LandscapeConfig] = None):
        """
        åˆå§‹åŒ–æ™¯è§‚åˆ†æå™¨
        
        Args:
            config: æ™¯è§‚åˆ†æé…ç½®
        """
        pass
    
    def compute_metrics(self, classification_map: np.ndarray,
                       metrics: List[str] = None) -> Dict[str, float]:
        """
        è®¡ç®—æ™¯è§‚æŒ‡æ ‡
        
        Args:
            classification_map: åˆ†ç±»ç»“æœå›¾
            metrics: æŒ‡æ ‡åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
            
        Returns:
            æŒ‡æ ‡å­—å…¸
            
        Available metrics:
            - 'patch_density': æ–‘å—å¯†åº¦
            - 'edge_density': è¾¹ç¼˜å¯†åº¦
            - 'largest_patch_index': æœ€å¤§æ–‘å—æŒ‡æ•°
            - 'shannon_diversity': é¦™å†œå¤šæ ·æ€§æŒ‡æ•°
            - 'simpson_diversity': è¾›æ™®æ£®å¤šæ ·æ€§æŒ‡æ•°
            - 'evenness': å‡åŒ€åº¦æŒ‡æ•°
            - 'aggregation_index': èšé›†æŒ‡æ•°
            - 'connectance': è¿é€šåº¦
            
        Example:
            >>> analyzer = LandscapeAnalyzer()
            >>> metrics = analyzer.compute_metrics(classification_map)
            >>> print(f"Shannon diversity: {metrics['shannon_diversity']:.3f}")
        """
        pass
    
    def patch_analysis(self, classification_map: np.ndarray) -> pd.DataFrame:
        """
        æ–‘å—åˆ†æ
        
        Args:
            classification_map: åˆ†ç±»ç»“æœå›¾
            
        Returns:
            æ–‘å—ç»Ÿè®¡DataFrame
            
        Columns:
            - patch_id: æ–‘å—ID
            - class_id: ç±»åˆ«ID
            - area: é¢ç§¯
            - perimeter: å‘¨é•¿
            - shape_index: å½¢çŠ¶æŒ‡æ•°
            - core_area: æ ¸å¿ƒåŒºé¢ç§¯
        """
        pass
    
    def connectivity_analysis(self, classification_map: np.ndarray,
                            class_id: int,
                            distance_threshold: float = 100) -> Dict[str, Any]:
        """
        è¿é€šæ€§åˆ†æ
        
        Args:
            classification_map: åˆ†ç±»ç»“æœå›¾
            class_id: ç›®æ ‡ç±»åˆ«ID
            distance_threshold: è·ç¦»é˜ˆå€¼ï¼ˆç±³ï¼‰
            
        Returns:
            è¿é€šæ€§åˆ†æç»“æœ
        """
        pass
```

---

## ğŸ“Š è¯„ä¼°æ¨¡å—

### ModelEvaluator

æ¨¡å‹è¯„ä¼°å™¨ï¼Œæä¾›å…¨é¢çš„æ€§èƒ½è¯„ä¼°åŠŸèƒ½ã€‚

```python
class ModelEvaluator:
    """æ¨¡å‹è¯„ä¼°å™¨
    
    æä¾›åˆ†ç±»ç²¾åº¦è¯„ä¼°ã€ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒã€é”™è¯¯åˆ†æç­‰åŠŸèƒ½ã€‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ–è¯„ä¼°å™¨"""
        pass
    
    def evaluate(self, y_true: np.ndarray, y_pred: np.ndarray,
                class_names: List[str] = None) -> Dict[str, Any]:
        """
        å…¨é¢è¯„ä¼°
        
        Args:
            y_true: çœŸå®æ ‡ç­¾
            y_pred: é¢„æµ‹æ ‡ç­¾
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
            
        Metrics:
            - overall_accuracy: æ€»ä½“ç²¾åº¦
            - kappa: Kappaç³»æ•°
            - f1_score: F1åˆ†æ•°
            - precision: ç²¾ç¡®ç‡
            - recall: å¬å›ç‡
            - confusion_matrix: æ··æ·†çŸ©é˜µ
            - per_class_accuracy: å„ç±»åˆ«ç²¾åº¦
            
        Example:
            >>> evaluator = ModelEvaluator()
            >>> results = evaluator.evaluate(y_true, y_pred, class_names)
            >>> print(f"Overall Accuracy: {results['overall_accuracy']:.3f}")
            >>> print(f"Kappa: {results['kappa']:.3f}")
        """
        pass
    
    def cross_validation(self, classifier: Classifier,
                        X: np.ndarray, y: np.ndarray,
                        cv: int = 5,
                        stratified: bool = True) -> Dict[str, Any]:
        """
        äº¤å‰éªŒè¯
        
        Args:
            classifier: åˆ†ç±»å™¨å®ä¾‹
            X: ç‰¹å¾æ•°æ®
            y: æ ‡ç­¾æ•°æ®
            cv: æŠ˜æ•°
            stratified: æ˜¯å¦åˆ†å±‚æŠ½æ ·
            
        Returns:
            äº¤å‰éªŒè¯ç»“æœ
            
        Example:
            >>> cv_results = evaluator.cross_validation(
            ...     classifier, X, y, cv=5
            ... )
            >>> print(f"CV Accuracy: {cv_results['mean_accuracy']:.3f} Â± {cv_results['std_accuracy']:.3f}")
        """
        pass
    
    def confusion_matrix(self, y_true: np.ndarray, y_pred: np.ndarray,
                        normalize: bool = False) -> np.ndarray:
        """
        è®¡ç®—æ··æ·†çŸ©é˜µ
        
        Args:
            y_true: çœŸå®æ ‡ç­¾
            y_pred: é¢„æµ‹æ ‡ç­¾
            normalize: æ˜¯å¦å½’ä¸€åŒ–
            
        Returns:
            æ··æ·†çŸ©é˜µ
        """
        pass
    
    def classification_report(self, y_true: np.ndarray, y_pred: np.ndarray,
                            class_names: List[str] = None) -> str:
        """
        ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
        
        Args:
            y_true: çœŸå®æ ‡ç­¾
            y_pred: é¢„æµ‹æ ‡ç­¾
            class_names: ç±»åˆ«åç§°
            
        Returns:
            åˆ†ç±»æŠ¥å‘Šå­—ç¬¦ä¸²
        """
        pass
```

### UncertaintyAnalyzer

ä¸ç¡®å®šæ€§åˆ†æå™¨ï¼Œè¯„ä¼°æ¨¡å‹é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚

```python
class UncertaintyAnalyzer:
    """ä¸ç¡®å®šæ€§åˆ†æå™¨"""
    
    def monte_carlo_dropout(self, model, X: np.ndarray,
                           n_samples: int = 100) -> np.ndarray:
        """
        Monte Carlo Dropoutä¸ç¡®å®šæ€§ä¼°è®¡
        
        Args:
            model: æ·±åº¦å­¦ä¹ æ¨¡å‹
            X: è¾“å…¥æ•°æ®
            n_samples: é‡‡æ ·æ¬¡æ•°
            
        Returns:
            ä¸ç¡®å®šæ€§ä¼°è®¡ç»“æœ (N_samples, N_classes, n_samples)
        """
        pass
    
    def predictive_entropy(self, predictions: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—é¢„æµ‹ç†µ
        
        Args:
            predictions: é¢„æµ‹æ¦‚ç‡ (N_samples, N_classes)
            
        Returns:
            é¢„æµ‹ç†µæ•°ç»„
        """
        pass
```

---

## ğŸ› ï¸ å·¥å…·æ¨¡å—

### Visualizer

å¯è§†åŒ–å·¥å…·ï¼Œæä¾›ä¸°å¯Œçš„å›¾è¡¨å’Œåœ°å›¾å±•ç¤ºåŠŸèƒ½ã€‚

```python
class Visualizer:
    """å¯è§†åŒ–å·¥å…·
    
    æä¾›åˆ†ç±»ç»“æœå¯è§†åŒ–ã€ç²¾åº¦è¯„ä¼°å›¾è¡¨ã€ç‰¹å¾åˆ†æå›¾ç­‰ã€‚
    """
    
    def plot_classification_map(self, classification_map: np.ndarray,
                              class_names: List[str] = None,
                              colors: List[str] = None,
                              title: str = 'Classification Map',
                              save_path: str = None):
        """
        ç»˜åˆ¶åˆ†ç±»ç»“æœå›¾
        
        Args:
            classification_map: åˆ†ç±»ç»“æœå›¾
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
            colors: ç±»åˆ«é¢œè‰²åˆ—è¡¨
            title: å›¾è¡¨æ ‡é¢˜
            save_path: ä¿å­˜è·¯å¾„
            
        Example:
            >>> visualizer = Visualizer()
            >>> visualizer.plot_classification_map(
            ...     result_map, 
            ...     class_names=['Water', 'Vegetation', 'Soil'],
            ...     save_path='classification_result.png'
            ... )
        """
        pass
    
    def plot_confusion_matrix(self, confusion_matrix: np.ndarray,
                            class_names: List[str] = None,
                            normalize: bool = False,
                            title: str = 'Confusion Matrix',
                            save_path: str = None):
        """
        ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        
        Args:
            confusion_matrix: æ··æ·†çŸ©é˜µ
            class_names: ç±»åˆ«åç§°
            normalize: æ˜¯å¦å½’ä¸€åŒ–æ˜¾ç¤º
            title: å›¾è¡¨æ ‡é¢˜
            save_path: ä¿å­˜è·¯å¾„
        """
        pass
    
    def plot_spectral_signatures(self, spectra: np.ndarray,
                                class_labels: np.ndarray,
                                wavelengths: np.ndarray = None,
                                class_names: List[str] = None,
                                title: str = 'Spectral Signatures',
                                save_path: str = None):
        """
        ç»˜åˆ¶å…‰è°±ç‰¹å¾æ›²çº¿
        
        Args:
            spectra: å…‰è°±æ•°æ® (N_samples, N_bands)
            class_labels: ç±»åˆ«æ ‡ç­¾
            wavelengths: æ³¢é•¿æ•°ç»„
            class_names: ç±»åˆ«åç§°
            title: å›¾è¡¨æ ‡é¢˜
            save_path: ä¿å­˜è·¯å¾„
        """
        pass
    
    def plot_feature_importance(self, importance: np.ndarray,
                              feature_names: List[str] = None,
                              top_k: int = 20,
                              title: str = 'Feature Importance',
                              save_path: str = None):
        """
        ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾
        
        Args:
            importance: ç‰¹å¾é‡è¦æ€§æ•°ç»„
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
            top_k: æ˜¾ç¤ºå‰kä¸ªé‡è¦ç‰¹å¾
            title: å›¾è¡¨æ ‡é¢˜
            save_path: ä¿å­˜è·¯å¾„
        """
        pass
```

### Logger

æ—¥å¿—ç®¡ç†å™¨ï¼Œæä¾›ç»“æ„åŒ–çš„æ—¥å¿—è®°å½•åŠŸèƒ½ã€‚

```python
def get_logger(name: str, level: str = 'INFO') -> logging.Logger:
    """
    è·å–æ—¥å¿—è®°å½•å™¨
    
    Args:
        name: æ—¥å¿—è®°å½•å™¨åç§°
        level: æ—¥å¿—çº§åˆ« ('DEBUG', 'INFO', 'WARNING', 'ERROR')
        
    Returns:
        é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨
        
    Example:
        >>> logger = get_logger(__name__)
        >>> logger.info("Processing started")
        >>> logger.error("An error occurred: %s", error_message)
    """
    pass
```

### IOUtils

è¾“å…¥è¾“å‡ºå·¥å…·ï¼Œæä¾›æ–‡ä»¶æ“ä½œçš„ä¾¿åˆ©å‡½æ•°ã€‚

```python
class IOUtils:
    """è¾“å…¥è¾“å‡ºå·¥å…·ç±»"""
    
    @staticmethod
    def save_geotiff(array: np.ndarray, 
                    output_path: str,
                    reference_path: str = None,
                    crs: str = None,
                    transform = None):
        """
        ä¿å­˜GeoTIFFæ–‡ä»¶
        
        Args:
            array: è¦ä¿å­˜çš„æ•°ç»„
            output_path: è¾“å‡ºè·¯å¾„
            reference_path: å‚è€ƒæ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºè·å–åœ°ç†ä¿¡æ¯ï¼‰
            crs: åæ ‡ç³»ç»Ÿ
            transform: ä»¿å°„å˜æ¢å‚æ•°
            
        Example:
            >>> IOUtils.save_geotiff(
            ...     classification_result, 
            ...     'output/result.tif',
            ...     reference_path='input/scene.tif'
            ... )
        """
        pass
    
    @staticmethod
    def load_config(config_path: str) -> Dict[str, Any]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ (.yaml, .json)
            
        Returns:
            é…ç½®å­—å…¸
        """
        pass
    
    @staticmethod
    def save_results(results: Dict[str, Any], 
                    output_dir: str,
                    format: str = 'json'):
        """
        ä¿å­˜ç»“æœ
        
        Args:
            results: ç»“æœå­—å…¸
            output_dir: è¾“å‡ºç›®å½•
            format: ä¿å­˜æ ¼å¼ ('json', 'pickle', 'yaml')
        """
        pass
```

---

## âš™ï¸ é…ç½®æ¨¡å—

### Config

é…ç½®ç®¡ç†ç±»ï¼Œæä¾›ç»Ÿä¸€çš„é…ç½®ç®¡ç†æ¥å£ã€‚

```python
@dataclass
class Config:
    """ä¸»é…ç½®ç±»
    
    ç»Ÿä¸€ç®¡ç†ç³»ç»Ÿçš„æ‰€æœ‰é…ç½®å‚æ•°ã€‚
    """
    
    data: DataConfig
    preprocessing: PreprocessingConfig
    features: FeatureConfig
    classification: ClassificationConfig
    evaluation: EvaluationConfig
    
    @classmethod
    def from_file(cls, config_path: str) -> 'Config':
        """
        ä»æ–‡ä»¶åŠ è½½é…ç½®
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            é…ç½®å¯¹è±¡
            
        Example:
            >>> config = Config.from_file('config/config.yaml')
            >>> print(config.classification.model_type)
        """
        pass
    
    @classmethod
    def from_default(cls) -> 'Config':
        """
        åˆ›å»ºé»˜è®¤é…ç½®
        
        Returns:
            é»˜è®¤é…ç½®å¯¹è±¡
        """
        pass
    
    def save(self, output_path: str):
        """
        ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
        
        Args:
            output_path: è¾“å‡ºè·¯å¾„
        """
        pass
    
    def validate(self) -> bool:
        """
        éªŒè¯é…ç½®æœ‰æ•ˆæ€§
        
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
            
        Raises:
            ConfigValidationError: é…ç½®æ— æ•ˆæ—¶
        """
        pass
    
    def update(self, **kwargs):
        """
        æ›´æ–°é…ç½®å‚æ•°
        
        Example:
            >>> config.update(
            ...     classification__model_type='hybrid_cnn',
            ...     features__vegetation_indices=['NDVI', 'EVI']
            ... )
        """
        pass
```

### å­é…ç½®ç±»

```python
@dataclass
class DataConfig:
    """æ•°æ®é…ç½®"""
    input_path: str = "data/raw/"
    output_path: str = "output/"
    file_format: str = "tif"
    cache_enabled: bool = True
    tile_size: int = 512
    overlap: int = 64

@dataclass
class PreprocessingConfig:
    """é¢„å¤„ç†é…ç½®"""
    radiometric_calibration: bool = True
    atmospheric_correction: str = "FLAASH"
    geometric_correction: bool = True
    noise_reduction: str = "MNF"
    bad_bands: List[int] = None

@dataclass
class FeatureConfig:
    """ç‰¹å¾æå–é…ç½®"""
    spectral_features: bool = True
    vegetation_indices: List[str] = None
    texture_features: bool = True
    spatial_features: bool = True
    pca_components: int = 50

@dataclass
class ClassificationConfig:
    """åˆ†ç±»é…ç½®"""
    model_type: str = "hybrid_cnn"
    training_ratio: float = 0.7
    validation_ratio: float = 0.15
    test_ratio: float = 0.15
    random_state: int = 42
    
    # æ¨¡å‹ç‰¹å®šå‚æ•°
    svm_params: Dict[str, Any] = None
    rf_params: Dict[str, Any] = None
    cnn_params: Dict[str, Any] = None

@dataclass
class EvaluationConfig:
    """è¯„ä¼°é…ç½®"""
    metrics: List[str] = None
    cross_validation: int = 5
    confidence_interval: float = 0.95
    significance_level: float = 0.05
```

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´å·¥ä½œæµç¤ºä¾‹

```python
from wetland_classification import Pipeline
from wetland_classification.config import Config

# 1. åŠ è½½é…ç½®
config = Config.from_file('config/config.yaml')

# 2. åˆ›å»ºæµæ°´çº¿
pipeline = Pipeline(config)

# 3. è¿è¡Œå®Œæ•´æµç¨‹
results = pipeline.run(
    input_data='data/raw/wetland_scene.tif',
    ground_truth='data/raw/ground_truth.shp',
    output_dir='output/results/'
)

# 4. æŸ¥çœ‹ç»“æœ
print(f"Classification completed!")
print(f"Overall Accuracy: {results['accuracy']:.3f}")
print(f"Kappa Coefficient: {results['kappa']:.3f}")
print(f"Output files saved to: {results['output_dir']}")
```

### è‡ªå®šä¹‰å·¥ä½œæµç¤ºä¾‹

```python
from wetland_classification.data import DataLoader
from wetland_classification.preprocessing import Preprocessor
from wetland_classification.features import FeatureExtractor
from wetland_classification.classification import Classifier
from wetland_classification.evaluation import ModelEvaluator

# 1. æ•°æ®åŠ è½½
loader = DataLoader()
data, metadata = loader.load_hyperspectral('scene.tif')
labels = loader.load_ground_truth('labels.shp')

# 2. æ•°æ®é¢„å¤„ç†
preprocessor = Preprocessor()
processed_data = preprocessor.process_all(data)

# 3. ç‰¹å¾æå–
extractor = FeatureExtractor()
features = extractor.extract_all(processed_data)

# 4. æ¨¡å‹è®­ç»ƒ
classifier = Classifier('hybrid_cnn')
classifier.fit(X_train, y_train, X_val, y_val)

# 5. æ¨¡å‹è¯„ä¼°
evaluator = ModelEvaluator()
results = evaluator.evaluate(y_test, y_pred)
print(f"Test Accuracy: {results['overall_accuracy']:.3f}")
```

---

## ğŸ”§ å¼‚å¸¸å¤„ç†

### è‡ªå®šä¹‰å¼‚å¸¸ç±»

```python
class WetlandClassificationError(Exception):
    """åŸºç¡€å¼‚å¸¸ç±»"""
    pass

class DataLoadError(WetlandClassificationError):
    """æ•°æ®åŠ è½½å¼‚å¸¸"""
    pass

class PreprocessingError(WetlandClassificationError):
    """é¢„å¤„ç†å¼‚å¸¸"""
    pass

class FeatureExtractionError(WetlandClassificationError):
    """ç‰¹å¾æå–å¼‚å¸¸"""
    pass

class ClassificationError(WetlandClassificationError):
    """åˆ†ç±»å¼‚å¸¸"""
    pass

class ConfigurationError(WetlandClassificationError):
    """é…ç½®å¼‚å¸¸"""
    pass
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### APIç›¸å…³é—®é¢˜

- ğŸ“§ **APIæ”¯æŒ**: api-support@example.com
- ğŸ“š **åœ¨çº¿æ–‡æ¡£**: https://api-docs.example.com
- ğŸ’» **ä»£ç ç¤ºä¾‹**: https://github.com/yourusername/wetland-examples
- ğŸ› **BugæŠ¥å‘Š**: https://github.com/yourusername/wetland-hyperspectral-classification/issues

### ç‰ˆæœ¬å…¼å®¹æ€§

å½“å‰APIç‰ˆæœ¬: **v1.0.0**

æ”¯æŒçš„Pythonç‰ˆæœ¬: **3.8+**

ä¸»è¦ä¾èµ–ç‰ˆæœ¬:
- NumPy: 1.21+
- Scikit-learn: 1.0+
- PyTorch: 1.12+
- Rasterio: 1.3+

---

*æœ¬APIæ–‡æ¡£æŒç»­æ›´æ–°ä¸­ï¼Œæœ€åæ›´æ–°æ—¶é—´: 2024å¹´6æœˆ30æ—¥*