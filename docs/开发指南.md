# æ¹¿åœ°é«˜å…‰è°±åˆ†ç±»ç³»ç»Ÿå¼€å‘æŒ‡å—
## Wetland Hyperspectral Classification System - Developer Guide

### ğŸ“‹ ç›®å½•

1. [å¼€å‘ç¯å¢ƒè®¾ç½®](#å¼€å‘ç¯å¢ƒè®¾ç½®)
2. [é¡¹ç›®æ¶æ„](#é¡¹ç›®æ¶æ„)
3. [ä»£ç è§„èŒƒ](#ä»£ç è§„èŒƒ)
4. [å¼€å‘æµç¨‹](#å¼€å‘æµç¨‹)
5. [æµ‹è¯•æŒ‡å—](#æµ‹è¯•æŒ‡å—)
6. [æ–‡æ¡£ç¼–å†™](#æ–‡æ¡£ç¼–å†™)
7. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
8. [æ‰©å±•å¼€å‘](#æ‰©å±•å¼€å‘)
9. [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)
10. [è´¡çŒ®æŒ‡å—](#è´¡çŒ®æŒ‡å—)

---

## ğŸ”§ å¼€å‘ç¯å¢ƒè®¾ç½®

### å¼€å‘å·¥å…·æ ˆ

```yaml
æ ¸å¿ƒå·¥å…·:
  - Python: 3.9+
  - Git: ç‰ˆæœ¬æ§åˆ¶
  - Docker: å®¹å™¨åŒ–éƒ¨ç½²
  - pytest: å•å…ƒæµ‹è¯•
  - black: ä»£ç æ ¼å¼åŒ–
  - flake8: ä»£ç æ£€æŸ¥
  - mypy: ç±»å‹æ£€æŸ¥
  - sphinx: æ–‡æ¡£ç”Ÿæˆ
  
IDEæ¨è:
  - PyCharm Professional
  - Visual Studio Code
  - Jupyter Lab
```

### å¼€å‘ç¯å¢ƒå®‰è£…

```bash
# 1. å…‹éš†å¼€å‘åˆ†æ”¯
git clone -b develop https://github.com/yourusername/wetland-hyperspectral-classification.git
cd wetland-hyperspectral-classification

# 2. åˆ›å»ºå¼€å‘ç¯å¢ƒ
conda create -n wetland-dev python=3.9
conda activate wetland-dev

# 3. å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt
pip install -e .

# 4. å®‰è£…pre-commité’©å­
pre-commit install

# 5. éªŒè¯å®‰è£…
python -m pytest tests/ -v
python -m black --check src/
python -m flake8 src/
```

### å¼€å‘ä¾èµ–æ¸…å•

```txt
# requirements-dev.txt
# æ ¸å¿ƒä¾èµ–
-r requirements.txt

# å¼€å‘å·¥å…·
pytest>=7.0.0
pytest-cov>=4.0.0
pytest-xdist>=3.0.0
black>=22.0.0
flake8>=5.0.0
isort>=5.10.0
mypy>=1.0.0
pre-commit>=2.20.0

# æ–‡æ¡£å·¥å…·
sphinx>=5.0.0
sphinx-rtd-theme>=1.0.0
myst-parser>=0.18.0

# æ€§èƒ½åˆ†æ
memory-profiler>=0.60.0
line-profiler>=4.0.0
py-spy>=0.3.0

# å¯è§†åŒ–
matplotlib>=3.5.0
seaborn>=0.11.0
plotly>=5.0.0
```

### IDEé…ç½®

#### VS Codeé…ç½® (.vscode/settings.json)

```json
{
    "python.defaultInterpreterPath": "./venv/bin/python",
    "python.formatting.provider": "black",
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.linting.mypyEnabled": true,
    "python.testing.pytestEnabled": true,
    "python.testing.pytestArgs": ["tests/"],
    "files.exclude": {
        "**/__pycache__": true,
        "**/*.pyc": true,
        ".pytest_cache": true,
        ".coverage": true,
        "htmlcov": true
    }
}
```

#### PyCharmé…ç½®

```yaml
ä»£ç é£æ ¼:
  - å¯ç”¨Blackæ ¼å¼åŒ–å™¨
  - è®¾ç½®è¡Œé•¿åº¦ä¸º88
  - å¯ç”¨ç±»å‹æ£€æŸ¥

æµ‹è¯•é…ç½®:
  - è®¾ç½®pytestä¸ºé»˜è®¤æµ‹è¯•è¿è¡Œå™¨
  - å¯ç”¨è¦†ç›–ç‡æŠ¥å‘Š
  - é…ç½®æµ‹è¯•æ¨¡æ¿

ç‰ˆæœ¬æ§åˆ¶:
  - é›†æˆGit
  - è®¾ç½®å¿½ç•¥æ–‡ä»¶
  - å¯ç”¨ä»£ç å®¡æŸ¥å·¥å…·
```

---

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

### æ•´ä½“æ¶æ„å›¾

```
æ¹¿åœ°é«˜å…‰è°±åˆ†ç±»ç³»ç»Ÿæ¶æ„

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ç”¨æˆ·æ¥å£å±‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CLIæ¥å£   â”‚  Webæ¥å£   â”‚  APIæ¥å£   â”‚  Jupyteræ¥å£        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚           â”‚           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ä¸šåŠ¡é€»è¾‘å±‚                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Pipeline   â”‚  é…ç½®ç®¡ç†   â”‚  å·¥ä½œæµå¼•æ“  â”‚  ç»“æœåˆ†æ        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚           â”‚           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ ¸å¿ƒç®—æ³•å±‚                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•°æ®å¤„ç†   â”‚  ç‰¹å¾æå–   â”‚  æœºå™¨å­¦ä¹    â”‚  æ·±åº¦å­¦ä¹         â”‚
â”‚  é¢„å¤„ç†     â”‚  ç©ºé—´åˆ†æ   â”‚  é›†æˆå­¦ä¹    â”‚  åå¤„ç†          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚           â”‚           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ•°æ®è®¿é—®å±‚                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•°æ®åŠ è½½   â”‚  æ ¼å¼è½¬æ¢   â”‚  ç¼“å­˜ç®¡ç†   â”‚  å­˜å‚¨ä¼˜åŒ–        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚           â”‚           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     åŸºç¡€è®¾æ–½å±‚                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ–‡ä»¶ç³»ç»Ÿ   â”‚  æ•°æ®åº“     â”‚  è®¡ç®—èµ„æº   â”‚  ç›‘æ§æ—¥å¿—        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ¨¡å—è®¾è®¡åŸåˆ™

#### 1. å•ä¸€èŒè´£åŸåˆ™ (SRP)
```python
# å¥½çš„è®¾è®¡ - æ¯ä¸ªç±»åªè´Ÿè´£ä¸€ä»¶äº‹
class SpectralFeatureExtractor:
    """åªè´Ÿè´£å…‰è°±ç‰¹å¾æå–"""
    def extract_spectral_features(self, data):
        pass

class VegetationIndexCalculator:
    """åªè´Ÿè´£æ¤è¢«æŒ‡æ•°è®¡ç®—"""
    def calculate_ndvi(self, nir, red):
        pass
```

#### 2. å¼€é—­åŸåˆ™ (OCP)
```python
# å¯æ‰©å±•çš„åˆ†ç±»å™¨åŸºç±»
from abc import ABC, abstractmethod

class BaseClassifier(ABC):
    @abstractmethod
    def fit(self, X, y):
        pass
    
    @abstractmethod
    def predict(self, X):
        pass

# æ–°åˆ†ç±»å™¨åªéœ€ç»§æ‰¿åŸºç±»
class TransformerClassifier(BaseClassifier):
    def fit(self, X, y):
        # å®ç°Transformeråˆ†ç±»å™¨
        pass
    
    def predict(self, X):
        # å®ç°é¢„æµ‹é€»è¾‘
        pass
```

#### 3. ä¾èµ–æ³¨å…¥åŸåˆ™ (DIP)
```python
class Pipeline:
    def __init__(
        self, 
        preprocessor: BasePreprocessor,
        feature_extractor: BaseFeatureExtractor,
        classifier: BaseClassifier
    ):
        self.preprocessor = preprocessor
        self.feature_extractor = feature_extractor
        self.classifier = classifier
```

### æ ¸å¿ƒæ¨¡å—è¯¦è§£

#### æ•°æ®å¤„ç†æ¨¡å— (wetland_classification.data)

```python
"""
æ•°æ®å¤„ç†æ¨¡å—æ¶æ„

DataLoader (æ•°æ®åŠ è½½å™¨)
â”œâ”€â”€ HyperspectralLoader (é«˜å…‰è°±æ•°æ®åŠ è½½)
â”œâ”€â”€ GroundTruthLoader (åœ°é¢çœŸå®æ•°æ®åŠ è½½)
â”œâ”€â”€ AuxiliaryDataLoader (è¾…åŠ©æ•°æ®åŠ è½½)
â””â”€â”€ CacheManager (ç¼“å­˜ç®¡ç†)

DataValidator (æ•°æ®éªŒè¯å™¨)
â”œâ”€â”€ FormatValidator (æ ¼å¼éªŒè¯)
â”œâ”€â”€ QualityValidator (è´¨é‡éªŒè¯)
â””â”€â”€ ConsistencyValidator (ä¸€è‡´æ€§éªŒè¯)

DataAugmentation (æ•°æ®å¢å¼º)
â”œâ”€â”€ GeometricAugmentation (å‡ ä½•å˜æ¢)
â”œâ”€â”€ SpectralAugmentation (å…‰è°±å˜æ¢)
â””â”€â”€ NoiseAugmentation (å™ªå£°æ·»åŠ )
"""

# ç¤ºä¾‹å®ç°
class DataLoader:
    def __init__(self, config: Config):
        self.config = config
        self.cache = CacheManager()
        self.validator = DataValidator()
    
    def load_hyperspectral(self, path: str) -> np.ndarray:
        # æ£€æŸ¥ç¼“å­˜
        if self.cache.exists(path):
            return self.cache.load(path)
        
        # åŠ è½½æ•°æ®
        data = self._load_raw_data(path)
        
        # éªŒè¯æ•°æ®
        self.validator.validate(data)
        
        # ç¼“å­˜æ•°æ®
        self.cache.save(path, data)
        
        return data
```

#### é¢„å¤„ç†æ¨¡å— (wetland_classification.preprocessing)

```python
"""
é¢„å¤„ç†æ¨¡å—æ¶æ„

Preprocessor (é¢„å¤„ç†å™¨)
â”œâ”€â”€ RadiometricCalibrator (è¾å°„å®šæ ‡)
â”œâ”€â”€ AtmosphericCorrector (å¤§æ°”æ ¡æ­£)
â”œâ”€â”€ GeometricCorrector (å‡ ä½•æ ¡æ­£)
â””â”€â”€ NoiseReducer (å™ªå£°å»é™¤)

PreprocessingPipeline (é¢„å¤„ç†æµæ°´çº¿)
â”œâ”€â”€ StepManager (æ­¥éª¤ç®¡ç†)
â”œâ”€â”€ ParameterManager (å‚æ•°ç®¡ç†)
â””â”€â”€ QualityController (è´¨é‡æ§åˆ¶)
"""

class Preprocessor:
    def __init__(self):
        self.steps = []
        self.quality_controller = QualityController()
    
    def add_step(self, step: PreprocessingStep):
        self.steps.append(step)
    
    def process(self, data: np.ndarray) -> np.ndarray:
        for step in self.steps:
            data = step.apply(data)
            # è´¨é‡æ£€æŸ¥
            self.quality_controller.check(data)
        return data
```

---

## ğŸ“ ä»£ç è§„èŒƒ

### Pythonä»£ç é£æ ¼

#### å‘½åè§„èŒƒ

```python
# ç±»åä½¿ç”¨å¸•æ–¯å¡å‘½åæ³•
class HyperspectralDataLoader:
    pass

# å‡½æ•°å’Œå˜é‡ä½¿ç”¨è›‡å½¢å‘½åæ³•
def extract_spectral_features(hyperspectral_data):
    feature_matrix = process_data(hyperspectral_data)
    return feature_matrix

# å¸¸é‡ä½¿ç”¨å…¨å¤§å†™
SPECTRAL_BANDS = 224
DEFAULT_TILE_SIZE = 512

# ç§æœ‰æ–¹æ³•ä½¿ç”¨ä¸‹åˆ’çº¿å‰ç¼€
class DataProcessor:
    def _validate_input(self, data):
        pass
    
    def _internal_process(self, data):
        pass
```

#### ç±»å‹æ³¨è§£

```python
from typing import List, Dict, Optional, Union, Tuple
import numpy as np

def extract_features(
    data: np.ndarray,
    feature_types: List[str],
    parameters: Optional[Dict[str, Union[int, float]]] = None
) -> Tuple[np.ndarray, List[str]]:
    """
    æå–é«˜å…‰è°±ç‰¹å¾
    
    Args:
        data: é«˜å…‰è°±æ•°æ® (H, W, Bands)
        feature_types: ç‰¹å¾ç±»å‹åˆ—è¡¨
        parameters: å¯é€‰çš„å‚æ•°å­—å…¸
        
    Returns:
        features: ç‰¹å¾çŸ©é˜µ (N_samples, N_features)
        feature_names: ç‰¹å¾åç§°åˆ—è¡¨
    """
    if parameters is None:
        parameters = {}
    
    # å®ç°ç‰¹å¾æå–é€»è¾‘
    features = np.array([])  # placeholder
    feature_names = []  # placeholder
    
    return features, feature_names
```

#### é”™è¯¯å¤„ç†

```python
class WetlandClassificationError(Exception):
    """åŸºç¡€å¼‚å¸¸ç±»"""
    pass

class DataLoadError(WetlandClassificationError):
    """æ•°æ®åŠ è½½å¼‚å¸¸"""
    pass

class PreprocessingError(WetlandClassificationError):
    """é¢„å¤„ç†å¼‚å¸¸"""
    pass

# ä½¿ç”¨ç¤ºä¾‹
def load_hyperspectral_data(path: str) -> np.ndarray:
    try:
        if not os.path.exists(path):
            raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        
        with rasterio.open(path) as src:
            data = src.read()
            
        if data.size == 0:
            raise DataLoadError(f"æ•°æ®æ–‡ä»¶ä¸ºç©º: {path}")
            
        return data
        
    except rasterio.RasterioIOError as e:
        raise DataLoadError(f"æ— æ³•è¯»å–æ•°æ®æ–‡ä»¶ {path}: {e}")
    except Exception as e:
        raise WetlandClassificationError(f"æœªçŸ¥é”™è¯¯: {e}")
```

#### æ—¥å¿—è®°å½•

```python
import logging
from wetland_classification.utils.logger import get_logger

logger = get_logger(__name__)

class DataProcessor:
    def __init__(self):
        self.logger = get_logger(self.__class__.__name__)
    
    def process_data(self, data: np.ndarray) -> np.ndarray:
        self.logger.info(f"å¼€å§‹å¤„ç†æ•°æ®ï¼Œå½¢çŠ¶: {data.shape}")
        
        try:
            # å¤„ç†é€»è¾‘
            processed_data = self._internal_process(data)
            self.logger.info("æ•°æ®å¤„ç†å®Œæˆ")
            return processed_data
            
        except Exception as e:
            self.logger.error(f"æ•°æ®å¤„ç†å¤±è´¥: {e}")
            raise
```

### é…ç½®æ–‡ä»¶è§„èŒƒ

```python
# config.py
from dataclasses import dataclass
from typing import Dict, List, Optional

@dataclass
class DataConfig:
    """æ•°æ®é…ç½®"""
    input_path: str
    output_path: str
    file_format: str = "tif"
    cache_enabled: bool = True

@dataclass
class PreprocessingConfig:
    """é¢„å¤„ç†é…ç½®"""
    radiometric_calibration: bool = True
    atmospheric_correction: str = "FLAASH"
    geometric_correction: bool = True
    noise_reduction: str = "MNF"

@dataclass
class Config:
    """ä¸»é…ç½®ç±»"""
    data: DataConfig
    preprocessing: PreprocessingConfig
    
    @classmethod
    def from_file(cls, path: str) -> 'Config':
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        import yaml
        with open(path, 'r') as f:
            config_dict = yaml.safe_load(f)
        return cls.from_dict(config_dict)
    
    @classmethod
    def from_dict(cls, config_dict: Dict) -> 'Config':
        """ä»å­—å…¸åˆ›å»ºé…ç½®"""
        return cls(
            data=DataConfig(**config_dict['data']),
            preprocessing=PreprocessingConfig(**config_dict['preprocessing'])
        )
```

---

## ğŸ”„ å¼€å‘æµç¨‹

### Gitå·¥ä½œæµ

#### åˆ†æ”¯ç­–ç•¥

```
main (ç”Ÿäº§åˆ†æ”¯)
â”œâ”€â”€ develop (å¼€å‘åˆ†æ”¯)
â”‚   â”œâ”€â”€ feature/new-classifier (åŠŸèƒ½åˆ†æ”¯)
â”‚   â”œâ”€â”€ feature/data-augmentation (åŠŸèƒ½åˆ†æ”¯)
â”‚   â””â”€â”€ bugfix/memory-leak (ä¿®å¤åˆ†æ”¯)
â”œâ”€â”€ release/v1.1.0 (å‘å¸ƒåˆ†æ”¯)
â””â”€â”€ hotfix/critical-bug (çƒ­ä¿®å¤åˆ†æ”¯)
```

#### æäº¤è§„èŒƒ

```bash
# æäº¤æ ¼å¼
<type>(<scope>): <subject>

<body>

<footer>

# ç±»å‹è¯´æ˜
feat: æ–°åŠŸèƒ½
fix: ä¿®å¤bug
docs: æ–‡æ¡£æ›´æ–°
style: ä»£ç æ ¼å¼åŒ–
refactor: é‡æ„
test: æµ‹è¯•
chore: æ„å»ºå·¥å…·æˆ–è¾…åŠ©å·¥å…·

# ç¤ºä¾‹
feat(classification): æ·»åŠ Vision Transformeråˆ†ç±»å™¨

- å®ç°Vision Transformeræ¶æ„
- æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶å¯è§†åŒ–
- æ”¯æŒå¤šå°ºåº¦å›¾åƒå—è®­ç»ƒ

Closes #123
```

#### ä»£ç å®¡æŸ¥æµç¨‹

```yaml
ä»£ç å®¡æŸ¥æ£€æŸ¥æ¸…å•:
  åŠŸèƒ½æ€§:
    - [ ] ä»£ç å®ç°ç¬¦åˆéœ€æ±‚
    - [ ] è¾¹ç•Œæ¡ä»¶å¤„ç†æ­£ç¡®
    - [ ] é”™è¯¯å¤„ç†å®Œå–„
    - [ ] æ€§èƒ½è¡¨ç°è‰¯å¥½
  
  ä»£ç è´¨é‡:
    - [ ] ä»£ç ç»“æ„æ¸…æ™°
    - [ ] å‘½åè§„èŒƒæ­£ç¡®
    - [ ] æ³¨é‡Šå……åˆ†
    - [ ] éµå¾ªè®¾è®¡åŸåˆ™
  
  æµ‹è¯•è¦†ç›–:
    - [ ] å•å…ƒæµ‹è¯•è¦†ç›–
    - [ ] é›†æˆæµ‹è¯•è¦†ç›–
    - [ ] è¾¹ç•Œæµ‹è¯•è¦†ç›–
    - [ ] æ€§èƒ½æµ‹è¯•è¦†ç›–
```

### æŒç»­é›†æˆ/æŒç»­éƒ¨ç½² (CI/CD)

#### GitHub Actionsé…ç½®

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, 3.10]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Run tests
      run: |
        python -m pytest tests/ --cov=src/wetland_classification --cov-report=xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3

  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - uses: actions/setup-python@v3
      with:
        python-version: 3.9
    
    - name: Install dependencies
      run: |
        pip install black flake8 mypy
    
    - name: Run linting
      run: |
        black --check src/
        flake8 src/
        mypy src/
```

---

## ğŸ§ª æµ‹è¯•æŒ‡å—

### æµ‹è¯•æ¡†æ¶

```python
# æµ‹è¯•ç»“æ„
tests/
â”œâ”€â”€ unit/                    # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_data/
â”‚   â”œâ”€â”€ test_preprocessing/
â”‚   â”œâ”€â”€ test_features/
â”‚   â””â”€â”€ test_classification/
â”œâ”€â”€ integration/             # é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ test_pipeline/
â”‚   â””â”€â”€ test_end_to_end/
â”œâ”€â”€ performance/             # æ€§èƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ test_memory_usage/
â”‚   â””â”€â”€ test_speed/
â””â”€â”€ fixtures/                # æµ‹è¯•å¤¹å…·
    â”œâ”€â”€ conftest.py
    â””â”€â”€ test_data/
```

### å•å…ƒæµ‹è¯•ç¤ºä¾‹

```python
# tests/unit/test_features/test_spectral.py
import pytest
import numpy as np
from wetland_classification.features.spectral import SpectralFeatureExtractor

class TestSpectralFeatureExtractor:
    @pytest.fixture
    def sample_data(self):
        """åˆ›å»ºæµ‹è¯•æ•°æ®"""
        return np.random.rand(100, 100, 224)
    
    @pytest.fixture
    def extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return SpectralFeatureExtractor()
    
    def test_extract_mean_spectrum(self, extractor, sample_data):
        """æµ‹è¯•å¹³å‡å…‰è°±æå–"""
        mean_spectrum = extractor.extract_mean_spectrum(sample_data)
        
        assert mean_spectrum.shape == (224,)
        assert not np.any(np.isnan(mean_spectrum))
        assert np.all(mean_spectrum >= 0)
    
    def test_extract_with_invalid_input(self, extractor):
        """æµ‹è¯•æ— æ•ˆè¾“å…¥å¤„ç†"""
        with pytest.raises(ValueError):
            extractor.extract_mean_spectrum(np.array([]))
    
    @pytest.mark.parametrize("bands", [50, 100, 224])
    def test_different_band_numbers(self, extractor, bands):
        """æµ‹è¯•ä¸åŒæ³¢æ®µæ•°"""
        data = np.random.rand(50, 50, bands)
        result = extractor.extract_mean_spectrum(data)
        assert result.shape == (bands,)
```

### é›†æˆæµ‹è¯•ç¤ºä¾‹

```python
# tests/integration/test_pipeline.py
import pytest
from wetland_classification import Pipeline
from wetland_classification.config import Config

class TestPipeline:
    @pytest.fixture
    def config(self):
        """æµ‹è¯•é…ç½®"""
        return Config.from_file('tests/fixtures/test_config.yaml')
    
    @pytest.fixture
    def sample_scene(self):
        """æ ·æœ¬åœºæ™¯æ•°æ®"""
        return 'tests/fixtures/sample_scene.tif'
    
    def test_complete_pipeline(self, config, sample_scene):
        """æµ‹è¯•å®Œæ•´æµæ°´çº¿"""
        pipeline = Pipeline(config)
        
        results = pipeline.run(
            input_data=sample_scene,
            output_dir='tests/output/'
        )
        
        # éªŒè¯ç»“æœ
        assert 'accuracy' in results
        assert results['accuracy'] > 0.5
        assert 'classification_map' in results
        assert results['classification_map'] is not None
```

### æ€§èƒ½æµ‹è¯•

```python
# tests/performance/test_memory_usage.py
import pytest
import psutil
import numpy as np
from wetland_classification.features import FeatureExtractor

def test_memory_usage_large_data():
    """æµ‹è¯•å¤§æ•°æ®é›†çš„å†…å­˜ä½¿ç”¨"""
    process = psutil.Process()
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    # åˆ›å»ºå¤§æ•°æ®é›† (1GB)
    data = np.random.rand(2000, 2000, 100).astype(np.float32)
    
    extractor = FeatureExtractor()
    features = extractor.extract_all(data)
    
    peak_memory = process.memory_info().rss / 1024 / 1024  # MB
    memory_usage = peak_memory - initial_memory
    
    # éªŒè¯å†…å­˜ä½¿ç”¨ä¸è¶…è¿‡4GB
    assert memory_usage < 4000, f"å†…å­˜ä½¿ç”¨è¿‡é«˜: {memory_usage:.2f} MB"
```

### æµ‹è¯•è¦†ç›–ç‡

```bash
# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest tests/ --cov=src/wetland_classification --cov-report=html --cov-report=term

# æŸ¥çœ‹è¦†ç›–ç‡è¦æ±‚
coverage report --fail-under=90
```

---

## ğŸ“š æ–‡æ¡£ç¼–å†™

### æ–‡æ¡£ç»“æ„

```
docs/
â”œâ”€â”€ source/
â”‚   â”œâ”€â”€ conf.py              # Sphinxé…ç½®
â”‚   â”œâ”€â”€ index.rst            # ä¸»é¡µ
â”‚   â”œâ”€â”€ user_guide/          # ç”¨æˆ·æŒ‡å—
â”‚   â”œâ”€â”€ developer_guide/     # å¼€å‘æŒ‡å—
â”‚   â”œâ”€â”€ api_reference/       # APIå‚è€ƒ
â”‚   â””â”€â”€ tutorials/           # æ•™ç¨‹
â”œâ”€â”€ build/                   # æ„å»ºè¾“å‡º
â””â”€â”€ requirements.txt         # æ–‡æ¡£ä¾èµ–
```

### Sphinxé…ç½®

```python
# docs/source/conf.py
import os
import sys
sys.path.insert(0, os.path.abspath('../../src'))

project = 'æ¹¿åœ°é«˜å…‰è°±åˆ†ç±»ç³»ç»Ÿ'
copyright = '2024, Research Team'
author = 'Research Team'
release = '1.0.0'

extensions = [
    'sphinx.ext.autodoc',
    'sphinx.ext.viewcode',
    'sphinx.ext.napoleon',
    'sphinx.ext.intersphinx',
    'myst_parser',
]

html_theme = 'sphinx_rtd_theme'
html_static_path = ['_static']

# autodocé…ç½®
autodoc_default_options = {
    'members': True,
    'member-order': 'bysource',
    'special-members': '__init__',
    'undoc-members': True,
    'exclude-members': '__weakref__'
}
```

### APIæ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ

```python
# æ–‡æ¡£å­—ç¬¦ä¸²ç¤ºä¾‹
class HyperspectralClassifier:
    """
    é«˜å…‰è°±æ•°æ®åˆ†ç±»å™¨
    
    è¯¥åˆ†ç±»å™¨ä½¿ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•å¯¹é«˜å…‰è°±æ•°æ®è¿›è¡Œåˆ†ç±»ï¼Œ
    æ”¯æŒå¤šç§ç½‘ç»œæ¶æ„å’Œè®­ç»ƒç­–ç•¥ã€‚
    
    Args:
        model_type (str): æ¨¡å‹ç±»å‹ï¼Œå¯é€‰å€¼åŒ…æ‹¬ 'svm', 'rf', 'cnn_3d'
        config (Config): é…ç½®å¯¹è±¡
        
    Attributes:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        feature_extractor: ç‰¹å¾æå–å™¨
        
    Example:
        >>> from wetland_classification.classification import HyperspectralClassifier
        >>> classifier = HyperspectralClassifier(model_type='cnn_3d')
        >>> classifier.fit(X_train, y_train)
        >>> predictions = classifier.predict(X_test)
        
    Note:
        è¯¥åˆ†ç±»å™¨éœ€è¦CUDAæ”¯æŒä»¥è·å¾—æœ€ä½³æ€§èƒ½
        
    See Also:
        TraditionalClassifier: ä¼ ç»Ÿæœºå™¨å­¦ä¹ åˆ†ç±»å™¨
        EnsembleClassifier: é›†æˆåˆ†ç±»å™¨
    """
    
    def __init__(self, model_type: str, config: Optional[Config] = None):
        """
        åˆå§‹åŒ–åˆ†ç±»å™¨
        
        Args:
            model_type: æ¨¡å‹ç±»å‹
            config: å¯é€‰çš„é…ç½®å¯¹è±¡
            
        Raises:
            ValueError: å½“model_typeä¸æ”¯æŒæ—¶
        """
        pass
    
    def fit(self, X: np.ndarray, y: np.ndarray) -> 'HyperspectralClassifier':
        """
        è®­ç»ƒåˆ†ç±»å™¨
        
        Args:
            X: è®­ç»ƒç‰¹å¾ï¼Œå½¢çŠ¶ä¸º (n_samples, n_features)
            y: è®­ç»ƒæ ‡ç­¾ï¼Œå½¢çŠ¶ä¸º (n_samples,)
            
        Returns:
            è®­ç»ƒå¥½çš„åˆ†ç±»å™¨å®ä¾‹
            
        Raises:
            ValueError: å½“è¾“å…¥æ•°æ®æ ¼å¼ä¸æ­£ç¡®æ—¶
        """
        pass
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### è®¡ç®—ä¼˜åŒ–

#### 1. å‘é‡åŒ–è®¡ç®—

```python
# é¿å…å¾ªç¯ï¼Œä½¿ç”¨NumPyå‘é‡åŒ–
# åçš„ç¤ºä¾‹
def calculate_ndvi_slow(nir, red):
    result = np.zeros_like(nir)
    for i in range(nir.shape[0]):
        for j in range(nir.shape[1]):
            result[i, j] = (nir[i, j] - red[i, j]) / (nir[i, j] + red[i, j])
    return result

# å¥½çš„ç¤ºä¾‹
def calculate_ndvi_fast(nir, red):
    return (nir - red) / (nir + red + 1e-8)  # æ·»åŠ å°æ•°é¿å…é™¤é›¶
```

#### 2. å¹¶è¡Œå¤„ç†

```python
from multiprocessing import Pool
from concurrent.futures import ThreadPoolExecutor
import numpy as np

def parallel_feature_extraction(data_chunks, n_workers=4):
    """å¹¶è¡Œç‰¹å¾æå–"""
    def extract_features_chunk(chunk):
        # ç‰¹å¾æå–é€»è¾‘
        return features
    
    with Pool(n_workers) as pool:
        feature_chunks = pool.map(extract_features_chunk, data_chunks)
    
    return np.concatenate(feature_chunks, axis=0)
```

#### 3. å†…å­˜ä¼˜åŒ–

```python
def memory_efficient_processing(large_image, tile_size=512):
    """å†…å­˜é«˜æ•ˆçš„å¤§å›¾åƒå¤„ç†"""
    h, w, bands = large_image.shape
    results = []
    
    for i in range(0, h, tile_size):
        for j in range(0, w, tile_size):
            # åˆ†å—å¤„ç†
            tile = large_image[i:i+tile_size, j:j+tile_size, :]
            processed_tile = process_tile(tile)
            results.append(processed_tile)
            
            # é‡Šæ”¾å†…å­˜
            del tile
            gc.collect()
    
    return combine_results(results)
```

### GPUåŠ é€Ÿ

```python
import torch
import torch.nn.functional as F

class GPUAcceleratedProcessor:
    def __init__(self, device='cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
    
    def process_on_gpu(self, data):
        """GPUåŠ é€Ÿå¤„ç†"""
        # è½¬æ¢ä¸ºPyTorchå¼ é‡
        tensor_data = torch.from_numpy(data).float().to(self.device)
        
        # GPUè®¡ç®—
        with torch.no_grad():
            processed = F.conv2d(tensor_data, kernel, padding=1)
        
        # è½¬æ¢å›NumPy
        return processed.cpu().numpy()
```

### ç¼“å­˜ç­–ç•¥

```python
from functools import lru_cache
import pickle
import hashlib

class SmartCache:
    def __init__(self, cache_dir='cache/'):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
    
    def _get_cache_key(self, *args, **kwargs):
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_str = str(args) + str(sorted(kwargs.items()))
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def cached_function(self, func):
        """ç¼“å­˜è£…é¥°å™¨"""
        def wrapper(*args, **kwargs):
            cache_key = self._get_cache_key(*args, **kwargs)
            cache_file = os.path.join(self.cache_dir, f"{cache_key}.pkl")
            
            if os.path.exists(cache_file):
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)
            
            result = func(*args, **kwargs)
            
            with open(cache_file, 'wb') as f:
                pickle.dump(result, f)
            
            return result
        return wrapper
```

---

## ğŸ”Œ æ‰©å±•å¼€å‘

### æ’ä»¶ç³»ç»Ÿ

```python
# æ’ä»¶åŸºç±»
class BasePlugin:
    """æ’ä»¶åŸºç±»"""
    name = "base_plugin"
    version = "1.0.0"
    
    def __init__(self, config):
        self.config = config
    
    def initialize(self):
        """æ’ä»¶åˆå§‹åŒ–"""
        pass
    
    def execute(self, data):
        """æ’ä»¶æ‰§è¡Œ"""
        raise NotImplementedError

# æ’ä»¶ç®¡ç†å™¨
class PluginManager:
    def __init__(self):
        self.plugins = {}
    
    def register_plugin(self, plugin_class):
        """æ³¨å†Œæ’ä»¶"""
        plugin = plugin_class()
        self.plugins[plugin.name] = plugin
    
    def load_plugins_from_directory(self, directory):
        """ä»ç›®å½•åŠ è½½æ’ä»¶"""
        for file in os.listdir(directory):
            if file.endswith('.py'):
                module = importlib.import_module(f"plugins.{file[:-3]}")
                # æŸ¥æ‰¾æ’ä»¶ç±»å¹¶æ³¨å†Œ
                pass
```

### è‡ªå®šä¹‰åˆ†ç±»å™¨å¼€å‘

```python
from wetland_classification.classification.base import BaseClassifier

class CustomClassifier(BaseClassifier):
    """è‡ªå®šä¹‰åˆ†ç±»å™¨ç¤ºä¾‹"""
    
    def __init__(self, **kwargs):
        super().__init__()
        self.model_params = kwargs
    
    def fit(self, X, y):
        """è®­ç»ƒå®ç°"""
        # è‡ªå®šä¹‰è®­ç»ƒé€»è¾‘
        self.model = self._build_model()
        self.model.fit(X, y)
        return self
    
    def predict(self, X):
        """é¢„æµ‹å®ç°"""
        return self.model.predict(X)
    
    def _build_model(self):
        """æ„å»ºæ¨¡å‹"""
        # è‡ªå®šä¹‰æ¨¡å‹æ„å»ºé€»è¾‘
        pass
```

### è‡ªå®šä¹‰ç‰¹å¾æå–å™¨

```python
from wetland_classification.features.base import BaseFeatureExtractor

class CustomFeatureExtractor(BaseFeatureExtractor):
    """è‡ªå®šä¹‰ç‰¹å¾æå–å™¨"""
    
    def extract(self, data):
        """æå–è‡ªå®šä¹‰ç‰¹å¾"""
        # å®ç°ç‰¹å¾æå–é€»è¾‘
        features = self._compute_custom_features(data)
        return features
    
    def _compute_custom_features(self, data):
        """è®¡ç®—è‡ªå®šä¹‰ç‰¹å¾"""
        # å…·ä½“å®ç°
        pass
```

---

## ğŸš€ éƒ¨ç½²æŒ‡å—

### DockeråŒ–éƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gdal-bin \
    libgdal-dev \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶æºä»£ç 
COPY src/ ./src/
COPY config/ ./config/

# å®‰è£…é¡¹ç›®
RUN pip install -e .

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app/src

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["python", "-m", "wetland_classification.server"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  wetland-api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./output:/app/output
    environment:
      - WETLAND_ENV=production
      - CUDA_VISIBLE_DEVICES=0
    
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
  
  postgres:
    image: postgres:13
    environment:
      POSTGRES_DB: wetland_classification
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
```

### äº‘å¹³å°éƒ¨ç½²

#### AWSéƒ¨ç½²

```yaml
# aws-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wetland-classification
spec:
  replicas: 3
  selector:
    matchLabels:
      app: wetland-classification
  template:
    metadata:
      labels:
        app: wetland-classification
    spec:
      containers:
      - name: wetland-api
        image: your-registry/wetland-classification:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "8Gi"
            cpu: "4"
        env:
        - name: WETLAND_ENV
          value: "production"
```

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

### è´¡çŒ®æµç¨‹

1. **Forké¡¹ç›®**
```bash
git clone https://github.com/yourusername/wetland-hyperspectral-classification.git
cd wetland-hyperspectral-classification
git remote add upstream https://github.com/original/wetland-hyperspectral-classification.git
```

2. **åˆ›å»ºåŠŸèƒ½åˆ†æ”¯**
```bash
git checkout -b feature/amazing-new-feature
```

3. **å¼€å‘å’Œæµ‹è¯•**
```bash
# å¼€å‘ä»£ç 
# è¿è¡Œæµ‹è¯•
pytest tests/
# æ£€æŸ¥ä»£ç è´¨é‡
black src/
flake8 src/
```

4. **æäº¤ä»£ç **
```bash
git add .
git commit -m "feat: æ·»åŠ amazing new feature"
git push origin feature/amazing-new-feature
```

5. **åˆ›å»ºPull Request**

### ä»£ç å®¡æŸ¥æ ‡å‡†

- [ ] ä»£ç åŠŸèƒ½æ­£ç¡®
- [ ] æµ‹è¯•è¦†ç›–å……åˆ†
- [ ] æ–‡æ¡£æ›´æ–°å®Œæ•´
- [ ] æ€§èƒ½å½±å“è¯„ä¼°
- [ ] å‘åå…¼å®¹æ€§
- [ ] ä»£ç é£æ ¼ä¸€è‡´

### å‘å¸ƒæµç¨‹

```bash
# 1. æ›´æ–°ç‰ˆæœ¬å·
bump2version minor  # æˆ– major/patch

# 2. æ›´æ–°CHANGELOG
# ç¼–è¾‘CHANGELOG.md

# 3. åˆ›å»ºå‘å¸ƒåˆ†æ”¯
git checkout -b release/v1.1.0

# 4. æœ€ç»ˆæµ‹è¯•
pytest tests/
python -m wetland_classification.tests.integration

# 5. åˆå¹¶åˆ°main
git checkout main
git merge release/v1.1.0

# 6. åˆ›å»ºæ ‡ç­¾
git tag v1.1.0
git push origin v1.1.0

# 7. å‘å¸ƒåˆ°PyPI
python setup.py sdist bdist_wheel
twine upload dist/*
```

---

## ğŸ“ å¼€å‘æ”¯æŒ

### è·å–å¸®åŠ©

- ğŸ“§ **å¼€å‘è€…é‚®ç®±**: dev-support@example.com
- ğŸ’¬ **å¼€å‘è€…ç¤¾åŒº**: [Slacké¢‘é“](https://wetland-dev.slack.com)
- ğŸ“š **æŠ€æœ¯æ–‡æ¡£**: [å¼€å‘è€…æ–‡æ¡£](https://dev-docs.example.com)
- ğŸ› **BugæŠ¥å‘Š**: [GitHub Issues](https://github.com/yourusername/wetland-hyperspectral-classification/issues)

### å¼€å‘èµ„æº

- ğŸ› ï¸ **å¼€å‘å·¥å…·**: [å·¥å…·æ¨èåˆ—è¡¨](development-tools.md)
- ğŸ“– **ç¼–ç è§„èŒƒ**: [è¯¦ç»†ç¼–ç è§„èŒƒ](coding-standards.md)
- ğŸ¥ **è§†é¢‘æ•™ç¨‹**: [å¼€å‘è€…è§†é¢‘æ•™ç¨‹](https://youtube.com/playlist)
- ğŸ“ **åšå®¢æ–‡ç« **: [æŠ€æœ¯åšå®¢](https://blog.example.com)

---

*æœ¬å¼€å‘æŒ‡å—æŒç»­æ›´æ–°ä¸­ï¼Œæœ€åæ›´æ–°æ—¶é—´: 2024å¹´6æœˆ30æ—¥*