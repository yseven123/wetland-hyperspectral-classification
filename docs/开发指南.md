# 湿地高光谱分类系统开发指南
## Wetland Hyperspectral Classification System - Developer Guide

### 📋 目录

1. [开发环境设置](#开发环境设置)
2. [项目架构](#项目架构)
3. [代码规范](#代码规范)
4. [开发流程](#开发流程)
5. [测试指南](#测试指南)
6. [文档编写](#文档编写)
7. [性能优化](#性能优化)
8. [扩展开发](#扩展开发)
9. [部署指南](#部署指南)
10. [贡献指南](#贡献指南)

---

## 🔧 开发环境设置

### 开发工具栈

```yaml
核心工具:
  - Python: 3.9+
  - Git: 版本控制
  - Docker: 容器化部署
  - pytest: 单元测试
  - black: 代码格式化
  - flake8: 代码检查
  - mypy: 类型检查
  - sphinx: 文档生成
  
IDE推荐:
  - PyCharm Professional
  - Visual Studio Code
  - Jupyter Lab
```

### 开发环境安装

```bash
# 1. 克隆开发分支
git clone -b develop https://github.com/yourusername/wetland-hyperspectral-classification.git
cd wetland-hyperspectral-classification

# 2. 创建开发环境
conda create -n wetland-dev python=3.9
conda activate wetland-dev

# 3. 安装开发依赖
pip install -r requirements-dev.txt
pip install -e .

# 4. 安装pre-commit钩子
pre-commit install

# 5. 验证安装
python -m pytest tests/ -v
python -m black --check src/
python -m flake8 src/
```

### 开发依赖清单

```txt
# requirements-dev.txt
# 核心依赖
-r requirements.txt

# 开发工具
pytest>=7.0.0
pytest-cov>=4.0.0
pytest-xdist>=3.0.0
black>=22.0.0
flake8>=5.0.0
isort>=5.10.0
mypy>=1.0.0
pre-commit>=2.20.0

# 文档工具
sphinx>=5.0.0
sphinx-rtd-theme>=1.0.0
myst-parser>=0.18.0

# 性能分析
memory-profiler>=0.60.0
line-profiler>=4.0.0
py-spy>=0.3.0

# 可视化
matplotlib>=3.5.0
seaborn>=0.11.0
plotly>=5.0.0
```

### IDE配置

#### VS Code配置 (.vscode/settings.json)

```json
{
    "python.defaultInterpreterPath": "./venv/bin/python",
    "python.formatting.provider": "black",
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.linting.mypyEnabled": true,
    "python.testing.pytestEnabled": true,
    "python.testing.pytestArgs": ["tests/"],
    "files.exclude": {
        "**/__pycache__": true,
        "**/*.pyc": true,
        ".pytest_cache": true,
        ".coverage": true,
        "htmlcov": true
    }
}
```

#### PyCharm配置

```yaml
代码风格:
  - 启用Black格式化器
  - 设置行长度为88
  - 启用类型检查

测试配置:
  - 设置pytest为默认测试运行器
  - 启用覆盖率报告
  - 配置测试模板

版本控制:
  - 集成Git
  - 设置忽略文件
  - 启用代码审查工具
```

---

## 🏗️ 项目架构

### 整体架构图

```
湿地高光谱分类系统架构

┌─────────────────────────────────────────────────────────────┐
│                     用户接口层                                │
├─────────────────────────────────────────────────────────────┤
│  CLI接口   │  Web接口   │  API接口   │  Jupyter接口        │
└─────────────┬───────────┬───────────┬─────────────────────┘
              │           │           │
┌─────────────▼───────────▼───────────▼─────────────────────┐
│                     业务逻辑层                               │
├─────────────────────────────────────────────────────────────┤
│  Pipeline   │  配置管理   │  工作流引擎  │  结果分析        │
└─────────────┬───────────┬───────────┬─────────────────────┘
              │           │           │
┌─────────────▼───────────▼───────────▼─────────────────────┐
│                     核心算法层                               │
├─────────────────────────────────────────────────────────────┤
│  数据处理   │  特征提取   │  机器学习   │  深度学习        │
│  预处理     │  空间分析   │  集成学习   │  后处理          │
└─────────────┬───────────┬───────────┬─────────────────────┘
              │           │           │
┌─────────────▼───────────▼───────────▼─────────────────────┐
│                     数据访问层                               │
├─────────────────────────────────────────────────────────────┤
│  数据加载   │  格式转换   │  缓存管理   │  存储优化        │
└─────────────┬───────────┬───────────┬─────────────────────┘
              │           │           │
┌─────────────▼───────────▼───────────▼─────────────────────┐
│                     基础设施层                               │
├─────────────────────────────────────────────────────────────┤
│  文件系统   │  数据库     │  计算资源   │  监控日志        │
└─────────────────────────────────────────────────────────────┘
```

### 模块设计原则

#### 1. 单一职责原则 (SRP)
```python
# 好的设计 - 每个类只负责一件事
class SpectralFeatureExtractor:
    """只负责光谱特征提取"""
    def extract_spectral_features(self, data):
        pass

class VegetationIndexCalculator:
    """只负责植被指数计算"""
    def calculate_ndvi(self, nir, red):
        pass
```

#### 2. 开闭原则 (OCP)
```python
# 可扩展的分类器基类
from abc import ABC, abstractmethod

class BaseClassifier(ABC):
    @abstractmethod
    def fit(self, X, y):
        pass
    
    @abstractmethod
    def predict(self, X):
        pass

# 新分类器只需继承基类
class TransformerClassifier(BaseClassifier):
    def fit(self, X, y):
        # 实现Transformer分类器
        pass
    
    def predict(self, X):
        # 实现预测逻辑
        pass
```

#### 3. 依赖注入原则 (DIP)
```python
class Pipeline:
    def __init__(
        self, 
        preprocessor: BasePreprocessor,
        feature_extractor: BaseFeatureExtractor,
        classifier: BaseClassifier
    ):
        self.preprocessor = preprocessor
        self.feature_extractor = feature_extractor
        self.classifier = classifier
```

### 核心模块详解

#### 数据处理模块 (wetland_classification.data)

```python
"""
数据处理模块架构

DataLoader (数据加载器)
├── HyperspectralLoader (高光谱数据加载)
├── GroundTruthLoader (地面真实数据加载)
├── AuxiliaryDataLoader (辅助数据加载)
└── CacheManager (缓存管理)

DataValidator (数据验证器)
├── FormatValidator (格式验证)
├── QualityValidator (质量验证)
└── ConsistencyValidator (一致性验证)

DataAugmentation (数据增强)
├── GeometricAugmentation (几何变换)
├── SpectralAugmentation (光谱变换)
└── NoiseAugmentation (噪声添加)
"""

# 示例实现
class DataLoader:
    def __init__(self, config: Config):
        self.config = config
        self.cache = CacheManager()
        self.validator = DataValidator()
    
    def load_hyperspectral(self, path: str) -> np.ndarray:
        # 检查缓存
        if self.cache.exists(path):
            return self.cache.load(path)
        
        # 加载数据
        data = self._load_raw_data(path)
        
        # 验证数据
        self.validator.validate(data)
        
        # 缓存数据
        self.cache.save(path, data)
        
        return data
```

#### 预处理模块 (wetland_classification.preprocessing)

```python
"""
预处理模块架构

Preprocessor (预处理器)
├── RadiometricCalibrator (辐射定标)
├── AtmosphericCorrector (大气校正)
├── GeometricCorrector (几何校正)
└── NoiseReducer (噪声去除)

PreprocessingPipeline (预处理流水线)
├── StepManager (步骤管理)
├── ParameterManager (参数管理)
└── QualityController (质量控制)
"""

class Preprocessor:
    def __init__(self):
        self.steps = []
        self.quality_controller = QualityController()
    
    def add_step(self, step: PreprocessingStep):
        self.steps.append(step)
    
    def process(self, data: np.ndarray) -> np.ndarray:
        for step in self.steps:
            data = step.apply(data)
            # 质量检查
            self.quality_controller.check(data)
        return data
```

---

## 📝 代码规范

### Python代码风格

#### 命名规范

```python
# 类名使用帕斯卡命名法
class HyperspectralDataLoader:
    pass

# 函数和变量使用蛇形命名法
def extract_spectral_features(hyperspectral_data):
    feature_matrix = process_data(hyperspectral_data)
    return feature_matrix

# 常量使用全大写
SPECTRAL_BANDS = 224
DEFAULT_TILE_SIZE = 512

# 私有方法使用下划线前缀
class DataProcessor:
    def _validate_input(self, data):
        pass
    
    def _internal_process(self, data):
        pass
```

#### 类型注解

```python
from typing import List, Dict, Optional, Union, Tuple
import numpy as np

def extract_features(
    data: np.ndarray,
    feature_types: List[str],
    parameters: Optional[Dict[str, Union[int, float]]] = None
) -> Tuple[np.ndarray, List[str]]:
    """
    提取高光谱特征
    
    Args:
        data: 高光谱数据 (H, W, Bands)
        feature_types: 特征类型列表
        parameters: 可选的参数字典
        
    Returns:
        features: 特征矩阵 (N_samples, N_features)
        feature_names: 特征名称列表
    """
    if parameters is None:
        parameters = {}
    
    # 实现特征提取逻辑
    features = np.array([])  # placeholder
    feature_names = []  # placeholder
    
    return features, feature_names
```

#### 错误处理

```python
class WetlandClassificationError(Exception):
    """基础异常类"""
    pass

class DataLoadError(WetlandClassificationError):
    """数据加载异常"""
    pass

class PreprocessingError(WetlandClassificationError):
    """预处理异常"""
    pass

# 使用示例
def load_hyperspectral_data(path: str) -> np.ndarray:
    try:
        if not os.path.exists(path):
            raise FileNotFoundError(f"数据文件不存在: {path}")
        
        with rasterio.open(path) as src:
            data = src.read()
            
        if data.size == 0:
            raise DataLoadError(f"数据文件为空: {path}")
            
        return data
        
    except rasterio.RasterioIOError as e:
        raise DataLoadError(f"无法读取数据文件 {path}: {e}")
    except Exception as e:
        raise WetlandClassificationError(f"未知错误: {e}")
```

#### 日志记录

```python
import logging
from wetland_classification.utils.logger import get_logger

logger = get_logger(__name__)

class DataProcessor:
    def __init__(self):
        self.logger = get_logger(self.__class__.__name__)
    
    def process_data(self, data: np.ndarray) -> np.ndarray:
        self.logger.info(f"开始处理数据，形状: {data.shape}")
        
        try:
            # 处理逻辑
            processed_data = self._internal_process(data)
            self.logger.info("数据处理完成")
            return processed_data
            
        except Exception as e:
            self.logger.error(f"数据处理失败: {e}")
            raise
```

### 配置文件规范

```python
# config.py
from dataclasses import dataclass
from typing import Dict, List, Optional

@dataclass
class DataConfig:
    """数据配置"""
    input_path: str
    output_path: str
    file_format: str = "tif"
    cache_enabled: bool = True

@dataclass
class PreprocessingConfig:
    """预处理配置"""
    radiometric_calibration: bool = True
    atmospheric_correction: str = "FLAASH"
    geometric_correction: bool = True
    noise_reduction: str = "MNF"

@dataclass
class Config:
    """主配置类"""
    data: DataConfig
    preprocessing: PreprocessingConfig
    
    @classmethod
    def from_file(cls, path: str) -> 'Config':
        """从文件加载配置"""
        import yaml
        with open(path, 'r') as f:
            config_dict = yaml.safe_load(f)
        return cls.from_dict(config_dict)
    
    @classmethod
    def from_dict(cls, config_dict: Dict) -> 'Config':
        """从字典创建配置"""
        return cls(
            data=DataConfig(**config_dict['data']),
            preprocessing=PreprocessingConfig(**config_dict['preprocessing'])
        )
```

---

## 🔄 开发流程

### Git工作流

#### 分支策略

```
main (生产分支)
├── develop (开发分支)
│   ├── feature/new-classifier (功能分支)
│   ├── feature/data-augmentation (功能分支)
│   └── bugfix/memory-leak (修复分支)
├── release/v1.1.0 (发布分支)
└── hotfix/critical-bug (热修复分支)
```

#### 提交规范

```bash
# 提交格式
<type>(<scope>): <subject>

<body>

<footer>

# 类型说明
feat: 新功能
fix: 修复bug
docs: 文档更新
style: 代码格式化
refactor: 重构
test: 测试
chore: 构建工具或辅助工具

# 示例
feat(classification): 添加Vision Transformer分类器

- 实现Vision Transformer架构
- 添加注意力机制可视化
- 支持多尺度图像块训练

Closes #123
```

#### 代码审查流程

```yaml
代码审查检查清单:
  功能性:
    - [ ] 代码实现符合需求
    - [ ] 边界条件处理正确
    - [ ] 错误处理完善
    - [ ] 性能表现良好
  
  代码质量:
    - [ ] 代码结构清晰
    - [ ] 命名规范正确
    - [ ] 注释充分
    - [ ] 遵循设计原则
  
  测试覆盖:
    - [ ] 单元测试覆盖
    - [ ] 集成测试覆盖
    - [ ] 边界测试覆盖
    - [ ] 性能测试覆盖
```

### 持续集成/持续部署 (CI/CD)

#### GitHub Actions配置

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, 3.10]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Run tests
      run: |
        python -m pytest tests/ --cov=src/wetland_classification --cov-report=xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3

  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - uses: actions/setup-python@v3
      with:
        python-version: 3.9
    
    - name: Install dependencies
      run: |
        pip install black flake8 mypy
    
    - name: Run linting
      run: |
        black --check src/
        flake8 src/
        mypy src/
```

---

## 🧪 测试指南

### 测试框架

```python
# 测试结构
tests/
├── unit/                    # 单元测试
│   ├── test_data/
│   ├── test_preprocessing/
│   ├── test_features/
│   └── test_classification/
├── integration/             # 集成测试
│   ├── test_pipeline/
│   └── test_end_to_end/
├── performance/             # 性能测试
│   ├── test_memory_usage/
│   └── test_speed/
└── fixtures/                # 测试夹具
    ├── conftest.py
    └── test_data/
```

### 单元测试示例

```python
# tests/unit/test_features/test_spectral.py
import pytest
import numpy as np
from wetland_classification.features.spectral import SpectralFeatureExtractor

class TestSpectralFeatureExtractor:
    @pytest.fixture
    def sample_data(self):
        """创建测试数据"""
        return np.random.rand(100, 100, 224)
    
    @pytest.fixture
    def extractor(self):
        """创建特征提取器"""
        return SpectralFeatureExtractor()
    
    def test_extract_mean_spectrum(self, extractor, sample_data):
        """测试平均光谱提取"""
        mean_spectrum = extractor.extract_mean_spectrum(sample_data)
        
        assert mean_spectrum.shape == (224,)
        assert not np.any(np.isnan(mean_spectrum))
        assert np.all(mean_spectrum >= 0)
    
    def test_extract_with_invalid_input(self, extractor):
        """测试无效输入处理"""
        with pytest.raises(ValueError):
            extractor.extract_mean_spectrum(np.array([]))
    
    @pytest.mark.parametrize("bands", [50, 100, 224])
    def test_different_band_numbers(self, extractor, bands):
        """测试不同波段数"""
        data = np.random.rand(50, 50, bands)
        result = extractor.extract_mean_spectrum(data)
        assert result.shape == (bands,)
```

### 集成测试示例

```python
# tests/integration/test_pipeline.py
import pytest
from wetland_classification import Pipeline
from wetland_classification.config import Config

class TestPipeline:
    @pytest.fixture
    def config(self):
        """测试配置"""
        return Config.from_file('tests/fixtures/test_config.yaml')
    
    @pytest.fixture
    def sample_scene(self):
        """样本场景数据"""
        return 'tests/fixtures/sample_scene.tif'
    
    def test_complete_pipeline(self, config, sample_scene):
        """测试完整流水线"""
        pipeline = Pipeline(config)
        
        results = pipeline.run(
            input_data=sample_scene,
            output_dir='tests/output/'
        )
        
        # 验证结果
        assert 'accuracy' in results
        assert results['accuracy'] > 0.5
        assert 'classification_map' in results
        assert results['classification_map'] is not None
```

### 性能测试

```python
# tests/performance/test_memory_usage.py
import pytest
import psutil
import numpy as np
from wetland_classification.features import FeatureExtractor

def test_memory_usage_large_data():
    """测试大数据集的内存使用"""
    process = psutil.Process()
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    # 创建大数据集 (1GB)
    data = np.random.rand(2000, 2000, 100).astype(np.float32)
    
    extractor = FeatureExtractor()
    features = extractor.extract_all(data)
    
    peak_memory = process.memory_info().rss / 1024 / 1024  # MB
    memory_usage = peak_memory - initial_memory
    
    # 验证内存使用不超过4GB
    assert memory_usage < 4000, f"内存使用过高: {memory_usage:.2f} MB"
```

### 测试覆盖率

```bash
# 运行测试并生成覆盖率报告
pytest tests/ --cov=src/wetland_classification --cov-report=html --cov-report=term

# 查看覆盖率要求
coverage report --fail-under=90
```

---

## 📚 文档编写

### 文档结构

```
docs/
├── source/
│   ├── conf.py              # Sphinx配置
│   ├── index.rst            # 主页
│   ├── user_guide/          # 用户指南
│   ├── developer_guide/     # 开发指南
│   ├── api_reference/       # API参考
│   └── tutorials/           # 教程
├── build/                   # 构建输出
└── requirements.txt         # 文档依赖
```

### Sphinx配置

```python
# docs/source/conf.py
import os
import sys
sys.path.insert(0, os.path.abspath('../../src'))

project = '湿地高光谱分类系统'
copyright = '2024, Research Team'
author = 'Research Team'
release = '1.0.0'

extensions = [
    'sphinx.ext.autodoc',
    'sphinx.ext.viewcode',
    'sphinx.ext.napoleon',
    'sphinx.ext.intersphinx',
    'myst_parser',
]

html_theme = 'sphinx_rtd_theme'
html_static_path = ['_static']

# autodoc配置
autodoc_default_options = {
    'members': True,
    'member-order': 'bysource',
    'special-members': '__init__',
    'undoc-members': True,
    'exclude-members': '__weakref__'
}
```

### API文档自动生成

```python
# 文档字符串示例
class HyperspectralClassifier:
    """
    高光谱数据分类器
    
    该分类器使用深度学习方法对高光谱数据进行分类，
    支持多种网络架构和训练策略。
    
    Args:
        model_type (str): 模型类型，可选值包括 'svm', 'rf', 'cnn_3d'
        config (Config): 配置对象
        
    Attributes:
        model: 训练好的模型
        feature_extractor: 特征提取器
        
    Example:
        >>> from wetland_classification.classification import HyperspectralClassifier
        >>> classifier = HyperspectralClassifier(model_type='cnn_3d')
        >>> classifier.fit(X_train, y_train)
        >>> predictions = classifier.predict(X_test)
        
    Note:
        该分类器需要CUDA支持以获得最佳性能
        
    See Also:
        TraditionalClassifier: 传统机器学习分类器
        EnsembleClassifier: 集成分类器
    """
    
    def __init__(self, model_type: str, config: Optional[Config] = None):
        """
        初始化分类器
        
        Args:
            model_type: 模型类型
            config: 可选的配置对象
            
        Raises:
            ValueError: 当model_type不支持时
        """
        pass
    
    def fit(self, X: np.ndarray, y: np.ndarray) -> 'HyperspectralClassifier':
        """
        训练分类器
        
        Args:
            X: 训练特征，形状为 (n_samples, n_features)
            y: 训练标签，形状为 (n_samples,)
            
        Returns:
            训练好的分类器实例
            
        Raises:
            ValueError: 当输入数据格式不正确时
        """
        pass
```

---

## ⚡ 性能优化

### 计算优化

#### 1. 向量化计算

```python
# 避免循环，使用NumPy向量化
# 坏的示例
def calculate_ndvi_slow(nir, red):
    result = np.zeros_like(nir)
    for i in range(nir.shape[0]):
        for j in range(nir.shape[1]):
            result[i, j] = (nir[i, j] - red[i, j]) / (nir[i, j] + red[i, j])
    return result

# 好的示例
def calculate_ndvi_fast(nir, red):
    return (nir - red) / (nir + red + 1e-8)  # 添加小数避免除零
```

#### 2. 并行处理

```python
from multiprocessing import Pool
from concurrent.futures import ThreadPoolExecutor
import numpy as np

def parallel_feature_extraction(data_chunks, n_workers=4):
    """并行特征提取"""
    def extract_features_chunk(chunk):
        # 特征提取逻辑
        return features
    
    with Pool(n_workers) as pool:
        feature_chunks = pool.map(extract_features_chunk, data_chunks)
    
    return np.concatenate(feature_chunks, axis=0)
```

#### 3. 内存优化

```python
def memory_efficient_processing(large_image, tile_size=512):
    """内存高效的大图像处理"""
    h, w, bands = large_image.shape
    results = []
    
    for i in range(0, h, tile_size):
        for j in range(0, w, tile_size):
            # 分块处理
            tile = large_image[i:i+tile_size, j:j+tile_size, :]
            processed_tile = process_tile(tile)
            results.append(processed_tile)
            
            # 释放内存
            del tile
            gc.collect()
    
    return combine_results(results)
```

### GPU加速

```python
import torch
import torch.nn.functional as F

class GPUAcceleratedProcessor:
    def __init__(self, device='cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
    
    def process_on_gpu(self, data):
        """GPU加速处理"""
        # 转换为PyTorch张量
        tensor_data = torch.from_numpy(data).float().to(self.device)
        
        # GPU计算
        with torch.no_grad():
            processed = F.conv2d(tensor_data, kernel, padding=1)
        
        # 转换回NumPy
        return processed.cpu().numpy()
```

### 缓存策略

```python
from functools import lru_cache
import pickle
import hashlib

class SmartCache:
    def __init__(self, cache_dir='cache/'):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
    
    def _get_cache_key(self, *args, **kwargs):
        """生成缓存键"""
        key_str = str(args) + str(sorted(kwargs.items()))
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def cached_function(self, func):
        """缓存装饰器"""
        def wrapper(*args, **kwargs):
            cache_key = self._get_cache_key(*args, **kwargs)
            cache_file = os.path.join(self.cache_dir, f"{cache_key}.pkl")
            
            if os.path.exists(cache_file):
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)
            
            result = func(*args, **kwargs)
            
            with open(cache_file, 'wb') as f:
                pickle.dump(result, f)
            
            return result
        return wrapper
```

---

## 🔌 扩展开发

### 插件系统

```python
# 插件基类
class BasePlugin:
    """插件基类"""
    name = "base_plugin"
    version = "1.0.0"
    
    def __init__(self, config):
        self.config = config
    
    def initialize(self):
        """插件初始化"""
        pass
    
    def execute(self, data):
        """插件执行"""
        raise NotImplementedError

# 插件管理器
class PluginManager:
    def __init__(self):
        self.plugins = {}
    
    def register_plugin(self, plugin_class):
        """注册插件"""
        plugin = plugin_class()
        self.plugins[plugin.name] = plugin
    
    def load_plugins_from_directory(self, directory):
        """从目录加载插件"""
        for file in os.listdir(directory):
            if file.endswith('.py'):
                module = importlib.import_module(f"plugins.{file[:-3]}")
                # 查找插件类并注册
                pass
```

### 自定义分类器开发

```python
from wetland_classification.classification.base import BaseClassifier

class CustomClassifier(BaseClassifier):
    """自定义分类器示例"""
    
    def __init__(self, **kwargs):
        super().__init__()
        self.model_params = kwargs
    
    def fit(self, X, y):
        """训练实现"""
        # 自定义训练逻辑
        self.model = self._build_model()
        self.model.fit(X, y)
        return self
    
    def predict(self, X):
        """预测实现"""
        return self.model.predict(X)
    
    def _build_model(self):
        """构建模型"""
        # 自定义模型构建逻辑
        pass
```

### 自定义特征提取器

```python
from wetland_classification.features.base import BaseFeatureExtractor

class CustomFeatureExtractor(BaseFeatureExtractor):
    """自定义特征提取器"""
    
    def extract(self, data):
        """提取自定义特征"""
        # 实现特征提取逻辑
        features = self._compute_custom_features(data)
        return features
    
    def _compute_custom_features(self, data):
        """计算自定义特征"""
        # 具体实现
        pass
```

---

## 🚀 部署指南

### Docker化部署

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    gdal-bin \
    libgdal-dev \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制源代码
COPY src/ ./src/
COPY config/ ./config/

# 安装项目
RUN pip install -e .

# 设置环境变量
ENV PYTHONPATH=/app/src

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["python", "-m", "wetland_classification.server"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  wetland-api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./output:/app/output
    environment:
      - WETLAND_ENV=production
      - CUDA_VISIBLE_DEVICES=0
    
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
  
  postgres:
    image: postgres:13
    environment:
      POSTGRES_DB: wetland_classification
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
```

### 云平台部署

#### AWS部署

```yaml
# aws-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wetland-classification
spec:
  replicas: 3
  selector:
    matchLabels:
      app: wetland-classification
  template:
    metadata:
      labels:
        app: wetland-classification
    spec:
      containers:
      - name: wetland-api
        image: your-registry/wetland-classification:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "8Gi"
            cpu: "4"
        env:
        - name: WETLAND_ENV
          value: "production"
```

---

## 🤝 贡献指南

### 贡献流程

1. **Fork项目**
```bash
git clone https://github.com/yourusername/wetland-hyperspectral-classification.git
cd wetland-hyperspectral-classification
git remote add upstream https://github.com/original/wetland-hyperspectral-classification.git
```

2. **创建功能分支**
```bash
git checkout -b feature/amazing-new-feature
```

3. **开发和测试**
```bash
# 开发代码
# 运行测试
pytest tests/
# 检查代码质量
black src/
flake8 src/
```

4. **提交代码**
```bash
git add .
git commit -m "feat: 添加amazing new feature"
git push origin feature/amazing-new-feature
```

5. **创建Pull Request**

### 代码审查标准

- [ ] 代码功能正确
- [ ] 测试覆盖充分
- [ ] 文档更新完整
- [ ] 性能影响评估
- [ ] 向后兼容性
- [ ] 代码风格一致

### 发布流程

```bash
# 1. 更新版本号
bump2version minor  # 或 major/patch

# 2. 更新CHANGELOG
# 编辑CHANGELOG.md

# 3. 创建发布分支
git checkout -b release/v1.1.0

# 4. 最终测试
pytest tests/
python -m wetland_classification.tests.integration

# 5. 合并到main
git checkout main
git merge release/v1.1.0

# 6. 创建标签
git tag v1.1.0
git push origin v1.1.0

# 7. 发布到PyPI
python setup.py sdist bdist_wheel
twine upload dist/*
```

---

## 📞 开发支持

### 获取帮助

- 📧 **开发者邮箱**: dev-support@example.com
- 💬 **开发者社区**: [Slack频道](https://wetland-dev.slack.com)
- 📚 **技术文档**: [开发者文档](https://dev-docs.example.com)
- 🐛 **Bug报告**: [GitHub Issues](https://github.com/yourusername/wetland-hyperspectral-classification/issues)

### 开发资源

- 🛠️ **开发工具**: [工具推荐列表](development-tools.md)
- 📖 **编码规范**: [详细编码规范](coding-standards.md)
- 🎥 **视频教程**: [开发者视频教程](https://youtube.com/playlist)
- 📝 **博客文章**: [技术博客](https://blog.example.com)

---

*本开发指南持续更新中，最后更新时间: 2024年6月30日*