{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 湿地高光谱数据探索分析\n",
    "## Wetland Hyperspectral Data Exploration\n",
    "\n",
    "本笔记本展示如何探索和分析高光谱遥感数据，包括数据加载、可视化、统计分析等。\n",
    "\n",
    "**学习目标：**\n",
    "- 了解高光谱数据的结构和特点\n",
    "- 掌握数据可视化的基本方法\n",
    "- 学会进行数据质量评估\n",
    "- 理解不同地物类型的光谱特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置图表样式\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"环境准备完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入湿地分类系统模块\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "try:\n",
    "    from wetland_classification.data import DataLoader\n",
    "    from wetland_classification.utils.visualization import Visualizer\n",
    "    from wetland_classification.utils.logger import get_logger\n",
    "    print(\"✅ 湿地分类系统模块导入成功\")\nexcept ImportError as e:\n",
    "    print(f\"❌ 模块导入失败: {e}\")\n",
    "    print(\"💡 请确保已正确安装湿地分类系统\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据路径配置\n",
    "data_dir = Path('../data/samples/demo_scene')\n",
    "\n",
    "# 检查数据是否存在\n",
    "if not data_dir.exists():\n",
    "    print(\"🔄 演示数据不存在，正在创建...\")\n",
    "    # 这里可以调用数据创建函数\n",
    "    # create_demo_data()\n",
    "    print(\"⚠️ 请先运行 examples/基础分类示例.py 创建演示数据\")\nelse:\n",
    "    print(f\"✅ 找到数据目录: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载高光谱数据\n",
    "hyperspectral_file = data_dir / 'hyperspectral_data.npy'\n",
    "labels_file = data_dir / 'ground_truth.npy'\n",
    "wavelengths_file = data_dir / 'wavelengths.npy'\n",
    "\n",
    "if hyperspectral_file.exists():\n",
    "    # 加载数据\n",
    "    hyperspectral_data = np.load(hyperspectral_file)\n",
    "    ground_truth = np.load(labels_file)\n",
    "    \n",
    "    # 尝试加载波长信息\n",
    "    if wavelengths_file.exists():\n",
    "        wavelengths = np.load(wavelengths_file)\n",
    "    else:\n",
    "        # 如果没有波长信息，创建模拟的波长数组\n",
    "        wavelengths = np.linspace(400, 2500, hyperspectral_data.shape[2])\n",
    "    \n",
    "    print(f\"📊 数据加载成功!\")\n",
    "    print(f\"   高光谱数据形状: {hyperspectral_data.shape}\")\n",
    "    print(f\"   标签数据形状: {ground_truth.shape}\")\n",
    "    print(f\"   波长范围: {wavelengths[0]:.1f} - {wavelengths[-1]:.1f} nm\")\n",
    "    print(f\"   光谱波段数: {len(wavelengths)}\")\nelse:\n",
    "    print(\"❌ 数据文件不存在，请先创建演示数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载类别信息\n",
    "import json\n",
    "\n",
    "class_info_file = data_dir / 'class_info.json'\n",
    "if class_info_file.exists():\n",
    "    with open(class_info_file, 'r', encoding='utf-8') as f:\n",
    "        class_info = json.load(f)\n",
    "    \n",
    "    # 转换键为整数\n",
    "    class_info = {int(k): v for k, v in class_info.items()}\n",
    "    \n",
    "    print(\"📋 类别信息:\")\n",
    "    for class_id, info in class_info.items():\n",
    "        print(f\"   {class_id}: {info['name']}\")\nelse:\n",
    "    # 创建默认类别信息\n",
    "    class_info = {\n",
    "        1: {'name': '水体', 'color': '#0000FF'},\n",
    "        2: {'name': '植被', 'color': '#00FF00'},\n",
    "        3: {'name': '土壤', 'color': '#8B4513'}\n",
    "    }\n",
    "    print(\"🔧 使用默认类别信息\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据基本信息探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据基本统计信息\n",
    "height, width, bands = hyperspectral_data.shape\n",
    "total_pixels = height * width\n",
    "\n",
    "print(\"📏 数据维度信息:\")\n",
    "print(f\"   空间尺寸: {height} × {width} 像素\")\n",
    "print(f\"   光谱波段: {bands} 个\")\n",
    "print(f\"   总像素数: {total_pixels:,}\")\n",
    "print(f\"   数据大小: {hyperspectral_data.nbytes / 1024**2:.1f} MB\")\n",
    "\n",
    "print(\"\\n📊 光谱数值统计:\")\n",
    "print(f\"   最小值: {np.min(hyperspectral_data):.4f}\")\n",
    "print(f\"   最大值: {np.max(hyperspectral_data):.4f}\")\n",
    "print(f\"   平均值: {np.mean(hyperspectral_data):.4f}\")\n",
    "print(f\"   标准差: {np.std(hyperspectral_data):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别分布统计\n",
    "unique_classes, counts = np.unique(ground_truth, return_counts=True)\n",
    "\n",
    "print(\"🏷️ 类别分布统计:\")\n",
    "class_stats = []\n",
    "for class_id, count in zip(unique_classes, counts):\n",
    "    percentage = count / total_pixels * 100\n",
    "    class_name = class_info.get(class_id, {}).get('name', f'类别{class_id}')\n",
    "    \n",
    "    if class_id == 0:\n",
    "        class_name = '背景'\n",
    "    \n",
    "    print(f\"   {class_name}: {count:,} 像素 ({percentage:.1f}%)\")\n",
    "    \n",
    "    if class_id > 0:  # 排除背景\n",
    "        class_stats.append({\n",
    "            'class_id': class_id,\n",
    "            'class_name': class_name,\n",
    "            'count': count,\n",
    "            'percentage': percentage\n",
    "        })\n",
    "\n",
    "# 转换为DataFrame便于分析\n",
    "class_df = pd.DataFrame(class_stats)\nprint(f\"\\n📈 有效类别数: {len(class_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 RGB合成图像显示\n",
    "def create_rgb_image(hyperspectral_data, wavelengths):\n",
    "    \"\"\"创建RGB合成图像\"\"\"\n",
    "    # 选择接近红、绿、蓝的波段\n",
    "    red_idx = np.argmin(np.abs(wavelengths - 670))    # 红光 ~670nm\n",
    "    green_idx = np.argmin(np.abs(wavelengths - 550))  # 绿光 ~550nm  \n",
    "    blue_idx = np.argmin(np.abs(wavelengths - 470))   # 蓝光 ~470nm\n",
    "    \n",
    "    # 提取RGB波段\n",
    "    red_band = hyperspectral_data[:, :, red_idx]\n",
    "    green_band = hyperspectral_data[:, :, green_idx]\n",
    "    blue_band = hyperspectral_data[:, :, blue_idx]\n",
    "    \n",
    "    # 归一化到0-1范围\n",
    "    def normalize_band(band):\n",
    "        band_min, band_max = np.percentile(band, [2, 98])  # 使用2%和98%分位数\n",
    "        normalized = (band - band_min) / (band_max - band_min)\n",
    "        return np.clip(normalized, 0, 1)\n",
    "    \n",
    "    rgb_image = np.stack([\n",
    "        normalize_band(red_band),\n",
    "        normalize_band(green_band),\n",
    "        normalize_band(blue_band)\n",
    "    ], axis=2)\n",
    "    \n",
    "    return rgb_image, (red_idx, green_idx, blue_idx)\n",
    "\n",
    "# 创建RGB图像\n",
    "rgb_image, rgb_indices = create_rgb_image(hyperspectral_data, wavelengths)\n",
    "\n",
    "print(f\"🌈 RGB合成波段:\")\n",
    "print(f\"   红光: 波段{rgb_indices[0]+1} ({wavelengths[rgb_indices[0]]:.1f} nm)\")\n",
    "print(f\"   绿光: 波段{rgb_indices[1]+1} ({wavelengths[rgb_indices[1]]:.1f} nm)\")\n",
    "print(f\"   蓝光: 波段{rgb_indices[2]+1} ({wavelengths[rgb_indices[2]]:.1f} nm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 显示RGB图像和标签图\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# RGB图像\n",
    "axes[0].imshow(rgb_image)\n",
    "axes[0].set_title('RGB合成图像', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 标签图\n",
    "# 创建颜色映射\n",
    "colors = ['black'] + [class_info.get(i, {}).get('color', '#CCCCCC') \n",
    "                      for i in range(1, len(class_info)+1)]\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "im = axes[1].imshow(ground_truth, cmap=cmap, vmin=0, vmax=len(colors)-1)\n",
    "axes[1].set_title('地面真实标签', fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 添加图例\n",
    "legend_elements = []\n",
    "for class_id, info in class_info.items():\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements.append(Patch(facecolor=info['color'], label=info['name']))\n",
    "\n",
    "axes[1].legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 类别分布饼图\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 饼图\n",
    "colors_pie = [class_info[row['class_id']]['color'] for _, row in class_df.iterrows()]\n",
    "wedges, texts, autotexts = ax1.pie(\n",
    "    class_df['percentage'], \n",
    "    labels=class_df['class_name'],\n",
    "    colors=colors_pie,\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90\n",
    ")\n",
    "ax1.set_title('类别面积分布', fontsize=14)\n",
    "\n",
    "# 条形图\n",
    "bars = ax2.bar(class_df['class_name'], class_df['count'], color=colors_pie, alpha=0.7)\n",
    "ax2.set_ylabel('像素数量')\n",
    "ax2.set_title('各类别像素统计', fontsize=14)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 添加数值标签\n",
    "for bar, count in zip(bars, class_df['count']):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100,\n",
    "             f'{count:,}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 光谱特征分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 提取各类别的光谱特征\n",
    "def extract_class_spectra(hyperspectral_data, ground_truth, class_info, sample_size=1000):\n",
    "    \"\"\"提取各类别的光谱样本\"\"\"\n",
    "    class_spectra = {}\n",
    "    \n",
    "    for class_id in class_info.keys():\n",
    "        # 找到该类别的像素位置\n",
    "        class_mask = ground_truth == class_id\n",
    "        class_pixels = hyperspectral_data[class_mask]\n",
    "        \n",
    "        if len(class_pixels) > 0:\n",
    "            # 随机采样减少数据量\n",
    "            if len(class_pixels) > sample_size:\n",
    "                indices = np.random.choice(len(class_pixels), sample_size, replace=False)\n",
    "                class_pixels = class_pixels[indices]\n",
    "            \n",
    "            class_spectra[class_id] = {\n",
    "                'name': class_info[class_id]['name'],\n",
    "                'color': class_info[class_id]['color'],\n",
    "                'spectra': class_pixels,\n",
    "                'mean': np.mean(class_pixels, axis=0),\n",
    "                'std': np.std(class_pixels, axis=0),\n",
    "                'count': len(class_pixels)\n",
    "            }\n",
    "    \n",
    "    return class_spectra\n",
    "\n",
    "# 提取光谱特征\n",
    "np.random.seed(42)  # 保证结果可重复\n",
    "class_spectra = extract_class_spectra(hyperspectral_data, ground_truth, class_info)\n",
    "\n",
    "print(\"🔬 光谱特征提取完成:\")\n",
    "for class_id, spec_data in class_spectra.items():\n",
    "    print(f\"   {spec_data['name']}: {spec_data['count']} 个样本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 绘制平均光谱曲线\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for class_id, spec_data in class_spectra.items():\n",
    "    mean_spectrum = spec_data['mean']\n",
    "    std_spectrum = spec_data['std']\n",
    "    color = spec_data['color']\n",
    "    name = spec_data['name']\n",
    "    \n",
    "    # 绘制平均光谱\n",
    "    plt.plot(wavelengths, mean_spectrum, color=color, linewidth=2, label=name)\n",
    "    \n",
    "    # 添加标准差阴影\n",
    "    plt.fill_between(wavelengths, \n",
    "                     mean_spectrum - std_spectrum,\n",
    "                     mean_spectrum + std_spectrum,\n",
    "                     color=color, alpha=0.2)\n",
    "\n",
    "plt.xlabel('波长 (nm)', fontsize=12)\n",
    "plt.ylabel('反射率', fontsize=12)\n",
    "plt.title('各类别平均光谱特征曲线', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 标注重要波段\n",
    "important_bands = {\n",
    "    'Blue': 470,\n",
    "    'Green': 550,\n",
    "    'Red': 670,\n",
    "    'NIR': 850,\n",
    "    'SWIR1': 1650,\n",
    "    'SWIR2': 2200\n",
    "}\n",
    "\n",
    "for band_name, wavelength in important_bands.items():\n",
    "    if wavelength >= wavelengths[0] and wavelength <= wavelengths[-1]:\n",
    "        plt.axvline(x=wavelength, color='gray', linestyle='--', alpha=0.5)\n",
    "        plt.text(wavelength, plt.ylim()[1]*0.9, band_name, \n",
    "                ha='center', fontsize=8, rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 光谱可分性分析\n",
    "def calculate_spectral_separability(spectra1, spectra2):\n",
    "    \"\"\"计算两个光谱类别的可分性（简化版本）\"\"\"\n",
    "    mean1, mean2 = np.mean(spectra1, axis=0), np.mean(spectra2, axis=0)\n",
    "    \n",
    "    # 计算光谱角距离\n",
    "    dot_product = np.dot(mean1, mean2)\n",
    "    norm_product = np.linalg.norm(mean1) * np.linalg.norm(mean2)\n",
    "    \n",
    "    if norm_product > 0:\n",
    "        spectral_angle = np.arccos(np.clip(dot_product / norm_product, -1, 1))\n",
    "        spectral_angle = np.degrees(spectral_angle)\n",
    "    else:\n",
    "        spectral_angle = 0\n",
    "    \n",
    "    # 计算欧氏距离\n",
    "    euclidean_dist = np.linalg.norm(mean1 - mean2)\n",
    "    \n",
    "    return spectral_angle, euclidean_dist\n",
    "\n",
    "# 计算类别间可分性\n",
    "separability_matrix = np.zeros((len(class_spectra), len(class_spectra)))\n",
    "class_ids = list(class_spectra.keys())\n",
    "class_names = [class_spectra[cid]['name'] for cid in class_ids]\n",
    "\n",
    "for i, class_id1 in enumerate(class_ids):\n",
    "    for j, class_id2 in enumerate(class_ids):\n",
    "        if i != j:\n",
    "            spectra1 = class_spectra[class_id1]['spectra']\n",
    "            spectra2 = class_spectra[class_id2]['spectra']\n",
    "            angle, _ = calculate_spectral_separability(spectra1, spectra2)\n",
    "            separability_matrix[i, j] = angle\n",
    "\n",
    "# 绘制可分性热力图\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(separability_matrix, \n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "            annot=True, \n",
    "            fmt='.1f',\n",
    "            cmap='viridis',\n",
    "            cbar_kws={'label': '光谱角距离 (度)'})\n",
    "\n",
    "plt.title('类别间光谱可分性矩阵', fontsize=14)\n",
    "plt.xlabel('类别', fontsize=12)\n",
    "plt.ylabel('类别', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 光谱可分性分析：\")\n",
    "print(\"   - 数值越大表示两个类别的光谱差异越大\")\n",
    "print(\"   - 深色表示相似度高，浅色表示差异大\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 关键波段分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 计算植被指数\n",
    "def calculate_vegetation_indices(hyperspectral_data, wavelengths):\n",
    "    \"\"\"计算植被指数\"\"\"\n",
    "    # 找到最接近的波段\n",
    "    def find_nearest_band(target_wavelength):\n",
    "        return np.argmin(np.abs(wavelengths - target_wavelength))\n",
    "    \n",
    "    # 定义关键波段\n",
    "    blue_idx = find_nearest_band(470)\n",
    "    green_idx = find_nearest_band(550)\n",
    "    red_idx = find_nearest_band(670)\n",
    "    red_edge_idx = find_nearest_band(720)\n",
    "    nir_idx = find_nearest_band(850)\n",
    "    \n",
    "    # 提取波段数据\n",
    "    blue = hyperspectral_data[:, :, blue_idx]\n",
    "    green = hyperspectral_data[:, :, green_idx]\n",
    "    red = hyperspectral_data[:, :, red_idx]\n",
    "    red_edge = hyperspectral_data[:, :, red_edge_idx]\n",
    "    nir = hyperspectral_data[:, :, nir_idx]\n",
    "    \n",
    "    # 计算植被指数\n",
    "    epsilon = 1e-8  # 避免除零\n",
    "    \n",
    "    ndvi = (nir - red) / (nir + red + epsilon)\n",
    "    evi = 2.5 * (nir - red) / (nir + 6 * red - 7.5 * blue + 1 + epsilon)\n",
    "    savi = 1.5 * (nir - red) / (nir + red + 0.5 + epsilon)\n",
    "    ndwi = (green - nir) / (green + nir + epsilon)\n",
    "    \n",
    "    indices = {\n",
    "        'NDVI': ndvi,\n",
    "        'EVI': evi,\n",
    "        'SAVI': savi,\n",
    "        'NDWI': ndwi\n",
    "    }\n",
    "    \n",
    "    band_info = {\n",
    "        'Blue': (blue_idx, wavelengths[blue_idx]),\n",
    "        'Green': (green_idx, wavelengths[green_idx]),\n",
    "        'Red': (red_idx, wavelengths[red_idx]),\n",
    "        'Red Edge': (red_edge_idx, wavelengths[red_edge_idx]),\n",
    "        'NIR': (nir_idx, wavelengths[nir_idx])\n",
    "    }\n",
    "    \n",
    "    return indices, band_info\n",
    "\n",
    "# 计算植被指数\n",
    "vegetation_indices, band_info = calculate_vegetation_indices(hyperspectral_data, wavelengths)\n",
    "\n",
    "print(\"🌱 关键波段信息：\")\n",
    "for name, (idx, wavelength) in band_info.items():\n",
    "    print(f\"   {name}: 波段{idx+1} ({wavelength:.1f} nm)\")\n",
    "\n",
    "print(\"\\n📊 植被指数统计：\")\n",
    "for name, index_data in vegetation_indices.items():\n",
    "    print(f\"   {name}: {np.min(index_data):.3f} ~ {np.max(index_data):.3f} (均值: {np.mean(index_data):.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 可视化植被指数\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "cmaps = ['RdYlGn', 'viridis', 'RdYlBu', 'RdBu_r']\n",
    "\n",
    "for i, (name, index_data) in enumerate(vegetation_indices.items()):\n",
    "    im = axes[i].imshow(index_data, cmap=cmaps[i])\n",
    "    axes[i].set_title(f'{name} 植被指数', fontsize=12)\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # 添加颜色条\n",
    "    cbar = plt.colorbar(im, ax=axes[i], shrink=0.8)\n",
    "    cbar.set_label(name, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 数据质量评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 检查数据完整性\n",
    "def assess_data_quality(hyperspectral_data, ground_truth):\n",
    "    \"\"\"评估数据质量\"\"\"\n",
    "    quality_report = {}\n",
    "    \n",
    "    # 检查缺失值\n",
    "    nan_pixels = np.isnan(hyperspectral_data).sum()\n",
    "    inf_pixels = np.isinf(hyperspectral_data).sum()\n",
    "    zero_pixels = (hyperspectral_data == 0).sum()\n",
    "    \n",
    "    quality_report['missing_data'] = {\n",
    "        'nan_pixels': int(nan_pixels),\n",
    "        'inf_pixels': int(inf_pixels),\n",
    "        'zero_pixels': int(zero_pixels),\n",
    "        'total_pixels': int(hyperspectral_data.size)\n",
    "    }\n",
    "    \n",
    "    # 检查数值范围\n",
    "    quality_report['value_range'] = {\n",
    "        'min_value': float(np.min(hyperspectral_data)),\n",
    "        'max_value': float(np.max(hyperspectral_data)),\n",
    "        'mean_value': float(np.mean(hyperspectral_data)),\n",
    "        'std_value': float(np.std(hyperspectral_data))\n",
    "    }\n",
    "    \n",
    "    # 检查异常波段\n",
    "    band_means = np.mean(hyperspectral_data, axis=(0, 1))\n",
    "    band_stds = np.std(hyperspectral_data, axis=(0, 1))\n",
    "    \n",
    "    # 识别异常波段（标准差过大或过小）\n",
    "    std_threshold_high = np.percentile(band_stds, 95)\n",
    "    std_threshold_low = np.percentile(band_stds, 5)\n",
    "    \n",
    "    noisy_bands = np.where(band_stds > std_threshold_high)[0]\n",
    "    low_variation_bands = np.where(band_stds < std_threshold_low)[0]\n",
    "    \n",
    "    quality_report['band_quality'] = {\n",
    "        'noisy_bands': noisy_bands.tolist(),\n",
    "        'low_variation_bands': low_variation_bands.tolist(),\n",
    "        'band_mean_range': [float(np.min(band_means)), float(np.max(band_means))],\n",
    "        'band_std_range': [float(np.min(band_stds)), float(np.max(band_stds))]\n",
    "    }\n",
    "    \n",
    "    # 检查标签质量\n",
    "    unique_labels = np.unique(ground_truth)\n",
    "    label_counts = np.bincount(ground_truth.ravel())\n",
    "    \n",
    "    quality_report['label_quality'] = {\n",
    "        'unique_labels': unique_labels.tolist(),\n",
    "        'label_counts': label_counts.tolist(),\n",
    "        'min_class_size': int(np.min(label_counts[unique_labels])),\n",
    "        'max_class_size': int(np.max(label_counts[unique_labels]))\n",
    "    }\n",
    "    \n",
    "    return quality_report\n",
    "\n",
    "# 执行质量评估\n",
    "quality_report = assess_data_quality(hyperspectral_data, ground_truth)\n",
    "\n",
    "print(\"🔍 数据质量评估报告:\")\n",
    "print(f\"\\n📊 缺失数据检查:\")\n",
    "missing = quality_report['missing_data']\n",
    "print(f\"   NaN像素: {missing['nan_pixels']:,}\")\n",
    "print(f\"   无穷大像素: {missing['inf_pixels']:,}\")\n",
    "print(f\"   零值像素: {missing['zero_pixels']:,} ({missing['zero_pixels']/missing['total_pixels']*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n📈 数值范围检查:\")\n",
    "value_range = quality_report['value_range']\n",
    "print(f\"   数值范围: {value_range['min_value']:.4f} ~ {value_range['max_value']:.4f}\")\n",
    "print(f\"   平均值: {value_range['mean_value']:.4f}\")\n",
    "print(f\"   标准差: {value_range['std_value']:.4f}\")\n",
    "\n",
    "print(f\"\\n🌈 波段质量检查:\")\n",
    "band_quality = quality_report['band_quality']\n",
    "print(f\"   噪声波段数: {len(band_quality['noisy_bands'])}\")\n",
    "print(f\"   低变异波段数: {len(band_quality['low_variation_bands'])}\")\n",
    "if band_quality['noisy_bands']:\n",
    "    print(f\"   噪声波段: {band_quality['noisy_bands'][:10]}{'...' if len(band_quality['noisy_bands']) > 10 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 可视化波段质量\n",
    "band_means = np.mean(hyperspectral_data, axis=(0, 1))\n",
    "band_stds = np.std(hyperspectral_data, axis=(0, 1))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# 波段平均值\n",
    "ax1.plot(wavelengths, band_means, 'b-', linewidth=1)\n",
    "ax1.set_ylabel('平均反射率', fontsize=12)\n",
    "ax1.set_title('各波段平均反射率', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 标记异常波段\n",
    "noisy_bands = quality_report['band_quality']['noisy_bands']\n",
    "if noisy_bands:\n",
    "    ax1.scatter(wavelengths[noisy_bands], band_means[noisy_bands], \n",
    "               color='red', s=30, label='噪声波段', zorder=5)\n",
    "    ax1.legend()\n",
    "\n",
    "# 波段标准差\n",
    "ax2.plot(wavelengths, band_stds, 'g-', linewidth=1)\n",
    "ax2.set_xlabel('波长 (nm)', fontsize=12)\n",
    "ax2.set_ylabel('标准差', fontsize=12)\n",
    "ax2.set_title('各波段标准差（变异程度）', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 标记异常波段\n",
    "if noisy_bands:\n",
    "    ax2.scatter(wavelengths[noisy_bands], band_stds[noisy_bands], \n",
    "               color='red', s=30, label='噪声波段', zorder=5)\n",
    "\n",
    "low_var_bands = quality_report['band_quality']['low_variation_bands']\n",
    "if low_var_bands:\n",
    "    ax2.scatter(wavelengths[low_var_bands], band_stds[low_var_bands], \n",
    "               color='orange', s=30, label='低变异波段', zorder=5)\n",
    "\n",
    "if noisy_bands or low_var_bands:\n",
    "    ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 数据探索总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 生成数据探索总结报告\n",
    "def generate_exploration_summary(hyperspectral_data, ground_truth, class_info, \n",
    "                                quality_report, class_spectra):\n",
    "    \"\"\"生成数据探索总结\"\"\"\n",
    "    summary = {}\n",
    "    \n",
    "    # 基本信息\n",
    "    height, width, bands = hyperspectral_data.shape\n",
    "    summary['basic_info'] = {\n",
    "        'spatial_size': f\"{height} × {width}\",\n",
    "        'spectral_bands': bands,\n",
    "        'total_pixels': height * width,\n",
    "        'data_size_mb': hyperspectral_data.nbytes / 1024**2,\n",
    "        'num_classes': len(class_info)\n",
    "    }\n",
    "    \n",
    "    # 类别平衡性\n",
    "    unique_classes, counts = np.unique(ground_truth, return_counts=True)\n",
    "    valid_classes = unique_classes[unique_classes > 0]  # 排除背景\n",
    "    valid_counts = counts[unique_classes > 0]\n",
    "    \n",
    "    balance_ratio = np.max(valid_counts) / np.min(valid_counts)\n",
    "    summary['class_balance'] = {\n",
    "        'balance_ratio': balance_ratio,\n",
    "        'is_balanced': balance_ratio < 5,  # 如果比例小于5认为是平衡的\n",
    "        'min_class_size': int(np.min(valid_counts)),\n",
    "        'max_class_size': int(np.max(valid_counts))\n",
    "    }\n",
    "    \n",
    "    # 光谱可分性\n",
    "    if len(class_spectra) > 1:\n",
    "        separability_scores = []\n",
    "        class_ids = list(class_spectra.keys())\n",
    "        \n",
    "        for i in range(len(class_ids)):\n",
    "            for j in range(i+1, len(class_ids)):\n",
    "                spectra1 = class_spectra[class_ids[i]]['spectra']\n",
    "                spectra2 = class_spectra[class_ids[j]]['spectra']\n",
    "                angle, _ = calculate_spectral_separability(spectra1, spectra2)\n",
    "                separability_scores.append(angle)\n",
    "        \n",
    "        summary['spectral_separability'] = {\n",
    "            'mean_separability': np.mean(separability_scores),\n",
    "            'min_separability': np.min(separability_scores),\n",
    "            'max_separability': np.max(separability_scores),\n",
    "            'well_separated': np.mean(separability_scores) > 10  # 角度大于10度认为可分\n",
    "        }\n",
    "    \n",
    "    # 数据质量\n",
    "    total_pixels = hyperspectral_data.size\n",
    "    problem_pixels = (quality_report['missing_data']['nan_pixels'] + \n",
    "                     quality_report['missing_data']['inf_pixels'])\n",
    "    \n",
    "    summary['data_quality'] = {\n",
    "        'quality_score': 100 * (1 - problem_pixels / total_pixels),\n",
    "        'has_missing_data': problem_pixels > 0,\n",
    "        'noisy_bands_ratio': len(quality_report['band_quality']['noisy_bands']) / bands,\n",
    "        'low_var_bands_ratio': len(quality_report['band_quality']['low_variation_bands']) / bands\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# 生成总结\n",
    "exploration_summary = generate_exploration_summary(\n",
    "    hyperspectral_data, ground_truth, class_info, quality_report, class_spectra\n",
    ")\n",
    "\n",
    "print(\"📋 数据探索总结报告\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n📊 基本信息:\")\n",
    "basic = exploration_summary['basic_info']\n",
    "print(f\"   空间尺寸: {basic['spatial_size']} 像素\")\n",
    "print(f\"   光谱波段: {basic['spectral_bands']} 个\")\n",
    "print(f\"   数据大小: {basic['data_size_mb']:.1f} MB\")\n",
    "print(f\"   类别数量: {basic['num_classes']} 个\")\n",
    "\n",
    "print(f\"\\n⚖️ 类别平衡性:\")\n",
    "balance = exploration_summary['class_balance']\n",
    "print(f\"   平衡状态: {'✅ 平衡' if balance['is_balanced'] else '⚠️ 不平衡'}\")\n",
    "print(f\"   平衡比例: {balance['balance_ratio']:.1f}:1\")\n",
    "print(f\"   样本量范围: {balance['min_class_size']:,} ~ {balance['max_class_size']:,}\")\n",
    "\n",
    "if 'spectral_separability' in exploration_summary:\n",
    "    print(f\"\\n🔬 光谱可分性:\")\n",
    "    sep = exploration_summary['spectral_separability']\n",
    "    print(f\"   可分性状态: {'✅ 良好' if sep['well_separated'] else '⚠️ 困难'}\")\n",
    "    print(f\"   平均角距离: {sep['mean_separability']:.1f}°\")\n",
    "    print(f\"   距离范围: {sep['min_separability']:.1f}° ~ {sep['max_separability']:.1f}°\")\n",
    "\n",
    "print(f\"\\n✅ 数据质量:\")\n",
    "quality = exploration_summary['data_quality']\n",
    "print(f\"   质量评分: {quality['quality_score']:.1f}/100\")\n",
    "print(f\"   数据完整性: {'✅ 完整' if not quality['has_missing_data'] else '⚠️ 有缺失'}\")\n",
    "print(f\"   噪声波段比例: {quality['noisy_bands_ratio']:.1%}\")\n",
    "print(f\"   低变异波段比例: {quality['low_var_bands_ratio']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.2 数据预处理建议\n",
    "def generate_preprocessing_recommendations(exploration_summary, quality_report):\n",
    "    \"\"\"基于探索结果生成预处理建议\"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    # 类别平衡建议\n",
    "    if not exploration_summary['class_balance']['is_balanced']:\n",
    "        recommendations.append({\n",
    "            'type': '类别平衡',\n",
    "            'priority': 'high',\n",
    "            'suggestion': '数据集存在类别不平衡，建议使用类别权重、过采样或欠采样技术'\n",
    "        })\n",
    "    \n",
    "    # 噪声波段处理\n",
    "    noisy_ratio = exploration_summary['data_quality']['noisy_bands_ratio']\n",
    "    if noisy_ratio > 0.1:\n",
    "        recommendations.append({\n",
    "            'type': '噪声处理',\n",
    "            'priority': 'medium',\n",
    "            'suggestion': f'检测到{noisy_ratio:.1%}的噪声波段，建议进行波段选择或噪声去除'\n",
    "        })\n",
    "    \n",
    "    # 低变异波段处理\n",
    "    low_var_ratio = exploration_summary['data_quality']['low_var_bands_ratio']\n",
    "    if low_var_ratio > 0.05:\n",
    "        recommendations.append({\n",
    "            'type': '特征选择',\n",
    "            'priority': 'low',\n",
    "            'suggestion': f'检测到{low_var_ratio:.1%}的低变异波段，可考虑去除以减少冗余'\n",
    "        })\n",
    "    \n",
    "    # 光谱可分性建议\n",
    "    if 'spectral_separability' in exploration_summary:\n",
    "        if not exploration_summary['spectral_separability']['well_separated']:\n",
    "            recommendations.append({\n",
    "                'type': '特征增强',\n",
    "                'priority': 'high',\n",
    "                'suggestion': '光谱可分性较低，建议提取植被指数、纹理特征等高级特征'\n",
    "            })\n",
    "    \n",
    "    # 数据归一化建议\n",
    "    value_range = quality_report['value_range']\n",
    "    if value_range['max_value'] > 1 or value_range['min_value'] < 0:\n",
    "        recommendations.append({\n",
    "            'type': '数据归一化',\n",
    "            'priority': 'medium',\n",
    "            'suggestion': '数据值域超出[0,1]范围，建议进行归一化或标准化处理'\n",
    "        })\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# 生成建议\n",
    "recommendations = generate_preprocessing_recommendations(exploration_summary, quality_report)\n",
    "\n",
    "print(\"\\n💡 预处理建议:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if recommendations:\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        priority_icon = {'high': '🔴', 'medium': '🟡', 'low': '🟢'}\n",
    "        print(f\"\\n{i}. {rec['type']} {priority_icon.get(rec['priority'], '⚪')}\")\n",
    "        print(f\"   {rec['suggestion']}\")\nelse:\n",
    "    print(\"\\n✅ 数据质量良好，无需特殊预处理\")\n",
    "\n",
    "print(\"\\n📚 下一步建议:\")\n",
    "print(\"   1. 根据以上建议进行数据预处理\")\n",
    "print(\"   2. 查看 '02_预处理流程.ipynb' 了解具体实现\")\n",
    "print(\"   3. 进行特征工程和模型训练\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 保存探索结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存探索结果\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# 创建输出目录\n",
    "output_dir = Path('../output/data_exploration')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 保存探索总结\n",
    "exploration_report = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'data_info': {\n",
    "        'data_path': str(data_dir),\n",
    "        'data_shape': hyperspectral_data.shape,\n",
    "        'wavelength_range': [float(wavelengths[0]), float(wavelengths[-1])],\n",
    "        'num_classes': len(class_info)\n",
    "    },\n",
    "    'exploration_summary': exploration_summary,\n",
    "    'quality_report': quality_report,\n",
    "    'recommendations': recommendations\n",
    "}\n",
    "\n",
    "# 保存为JSON文件\n",
    "with open(output_dir / 'exploration_report.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(exploration_report, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 保存植被指数\n",
    "np.savez_compressed(output_dir / 'vegetation_indices.npz', **vegetation_indices)\n",
    "\n",
    "# 保存类别光谱特征\n",
    "spectral_data = {}\n",
    "for class_id, spec_data in class_spectra.items():\n",
    "    spectral_data[f'class_{class_id}_mean'] = spec_data['mean']\n",
    "    spectral_data[f'class_{class_id}_std'] = spec_data['std']\n",
    "\n",
    "np.savez_compressed(output_dir / 'class_spectra.npz', \n",
    "                   wavelengths=wavelengths, **spectral_data)\n",
    "\n",
    "print(f\"💾 探索结果已保存到: {output_dir}\")\n",
    "print(f\"   - exploration_report.json: 完整探索报告\")\n",
    "print(f\"   - vegetation_indices.npz: 植被指数数据\")\n",
    "print(f\"   - class_spectra.npz: 类别光谱特征\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 数据探索完成!\n",
    "\n",
    "通过本笔记本，我们完成了对湿地高光谱数据的全面探索分析，包括：\n",
    "\n",
    "### ✅ 主要成果：\n",
    "1. **数据基本信息**: 了解了数据的维度、大小和基本统计特性\n",
    "2. **可视化分析**: 创建了RGB图像、标签图和类别分布图\n",
    "3. **光谱特征分析**: 提取并分析了各类别的光谱特征曲线\n",
    "4. **可分性评估**: 计算了类别间的光谱可分性\n",
    "5. **植被指数计算**: 计算了NDVI、EVI、SAVI、NDWI等关键指数\n",
    "6. **数据质量评估**: 全面评估了数据质量并识别潜在问题\n",
    "7. **预处理建议**: 基于分析结果提供了针对性的预处理建议\n",
    "\n",
    "### 📚 下一步学习：\n",
    "- **02_预处理流程.ipynb**: 学习数据预处理的具体方法\n",
    "- **03_特征工程.ipynb**: 深入了解特征提取和工程\n",
    "- **04_模型训练.ipynb**: 掌握模型训练和调优\n",
    "- **05_结果分析.ipynb**: 学习结果分析和评估\n",
    "- **06_景观分析.ipynb**: 了解景观格局分析方法\n",
    "\n",
    "### 💡 关键收获：\n",
    "- 高光谱数据包含丰富的光谱信息，每个地物类型都有独特的光谱特征\n",
    "- 植被指数是区分不同地物类型的重要特征\n",
    "- 数据质量评估是成功分类的重要前提\n",
    "- 类别平衡性和光谱可分性直接影响分类效果\n",
    "\n",
    "继续探索更多高级功能，祝您学习愉快！🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}